{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1d184c6610b40a1b2d8621c12860c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2efcc7924c44333a440ee7c9c5f6936",
              "IPY_MODEL_7c06f7e4d578430fbd4e6a00374d639b",
              "IPY_MODEL_838866e74dc84a56b4aa62a0b6ecf2fc"
            ],
            "layout": "IPY_MODEL_47fde11dd2914090958715a678736fa4"
          }
        },
        "c2efcc7924c44333a440ee7c9c5f6936": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0094cc03aa1e446eb569351c9ef849c3",
            "placeholder": "​",
            "style": "IPY_MODEL_583c13d2f4034924b9b6f4078538328d",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "7c06f7e4d578430fbd4e6a00374d639b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df80ea617c6e4a248e3e80f63d47ec71",
            "max": 159,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_309d2843ccbf4ab0b24fa53765971046",
            "value": 159
          }
        },
        "838866e74dc84a56b4aa62a0b6ecf2fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88feb26cdffc48e5ae028992e7de3907",
            "placeholder": "​",
            "style": "IPY_MODEL_969750d807814a2f8d4b5019d1a3538f",
            "value": " 159/159 [00:00&lt;00:00, 3.36kB/s]"
          }
        },
        "47fde11dd2914090958715a678736fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0094cc03aa1e446eb569351c9ef849c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "583c13d2f4034924b9b6f4078538328d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df80ea617c6e4a248e3e80f63d47ec71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309d2843ccbf4ab0b24fa53765971046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88feb26cdffc48e5ae028992e7de3907": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969750d807814a2f8d4b5019d1a3538f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d02168d183544029bc452aa6d77ed6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_41118369599846b78934840d7ec64a83",
              "IPY_MODEL_d6f25dcbdc524a96a5a7da6ca5e7b17e",
              "IPY_MODEL_3357ad4e4dde466ea77e34eb99424529"
            ],
            "layout": "IPY_MODEL_c2b6944a94734448aaf7147661d9a810"
          }
        },
        "41118369599846b78934840d7ec64a83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30623f74d5c54ba1b88eed1d28437cc1",
            "placeholder": "​",
            "style": "IPY_MODEL_092aa43ed8e740b2af08f0280b7af57e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d6f25dcbdc524a96a5a7da6ca5e7b17e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9392dd13e155457eb6981d57151f1f89",
            "max": 163,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6203b183b3e42dd9863928ae2b0e654",
            "value": 163
          }
        },
        "3357ad4e4dde466ea77e34eb99424529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d099577757214eb9b086d285828e7091",
            "placeholder": "​",
            "style": "IPY_MODEL_cbf6162e2d824d69b73ebcfbf60ada14",
            "value": " 163/163 [00:00&lt;00:00, 2.21kB/s]"
          }
        },
        "c2b6944a94734448aaf7147661d9a810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30623f74d5c54ba1b88eed1d28437cc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "092aa43ed8e740b2af08f0280b7af57e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9392dd13e155457eb6981d57151f1f89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6203b183b3e42dd9863928ae2b0e654": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d099577757214eb9b086d285828e7091": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbf6162e2d824d69b73ebcfbf60ada14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f159e349464349c9a20baf4f78c3409c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ae27b2acb93b46e48a856f24413af77e",
              "IPY_MODEL_a581b5e792454f60b8998f0cc5abf4fc",
              "IPY_MODEL_52c1a27fae434170be870d4595197c44"
            ],
            "layout": "IPY_MODEL_729b3e494a47433f8d162fafbb7039b4"
          }
        },
        "ae27b2acb93b46e48a856f24413af77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5df899690be4645bffb477613a1fc9f",
            "placeholder": "​",
            "style": "IPY_MODEL_0a839fb745fd447fb9a4e3e3bdac016a",
            "value": "config.json: 100%"
          }
        },
        "a581b5e792454f60b8998f0cc5abf4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7321738e6fc1456db65a983b4a6a6837",
            "max": 843,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097a8210a11f4f50ae8583ce53f2d8d3",
            "value": 843
          }
        },
        "52c1a27fae434170be870d4595197c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e745f8185857400ca3b9ca098f8a98f7",
            "placeholder": "​",
            "style": "IPY_MODEL_2d24d079910845d9b1e0e5ac12407b41",
            "value": " 843/843 [00:00&lt;00:00, 15.9kB/s]"
          }
        },
        "729b3e494a47433f8d162fafbb7039b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5df899690be4645bffb477613a1fc9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a839fb745fd447fb9a4e3e3bdac016a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7321738e6fc1456db65a983b4a6a6837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097a8210a11f4f50ae8583ce53f2d8d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e745f8185857400ca3b9ca098f8a98f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d24d079910845d9b1e0e5ac12407b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd3338d9bf8249e8a103e049b482b578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7311fb3bc1484d65b9c51a52d4371ac1",
              "IPY_MODEL_db04469e86a040de9569ffafee99009f",
              "IPY_MODEL_73e9d59dd27b4894bc0b7c7d1435eb93"
            ],
            "layout": "IPY_MODEL_1a5a7f3fa0f5472488fe51b99e6594e2"
          }
        },
        "7311fb3bc1484d65b9c51a52d4371ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d8a318b0af743b6b13b66e875ab1d27",
            "placeholder": "​",
            "style": "IPY_MODEL_5f2892befc904ee59a819dbdd96d9ca5",
            "value": "vocab.json: 100%"
          }
        },
        "db04469e86a040de9569ffafee99009f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858e79516bc44842b36718807649c544",
            "max": 291,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a029b3296354ea2ae8c4548dad584e1",
            "value": 291
          }
        },
        "73e9d59dd27b4894bc0b7c7d1435eb93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f60b203f2d564885b02ba454ed052d79",
            "placeholder": "​",
            "style": "IPY_MODEL_d1c43f9f659d4c829e92c3ea95ce5fcf",
            "value": " 291/291 [00:00&lt;00:00, 5.22kB/s]"
          }
        },
        "1a5a7f3fa0f5472488fe51b99e6594e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d8a318b0af743b6b13b66e875ab1d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2892befc904ee59a819dbdd96d9ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "858e79516bc44842b36718807649c544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a029b3296354ea2ae8c4548dad584e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f60b203f2d564885b02ba454ed052d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c43f9f659d4c829e92c3ea95ce5fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff0d76aa27954415ad099ca540148727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cf3f82412994332b09789f09a0d4a67",
              "IPY_MODEL_f7529535dbde42868b377db6cd705ca3",
              "IPY_MODEL_e8f1b8251f96488098816e4ce426af40"
            ],
            "layout": "IPY_MODEL_9ef961f656484abaaa467a72166bb161"
          }
        },
        "2cf3f82412994332b09789f09a0d4a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a1570957b654c0dba8bf813e5127413",
            "placeholder": "​",
            "style": "IPY_MODEL_b226af00cd574a36bbb80fbe1b68489a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "f7529535dbde42868b377db6cd705ca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5e92409b0b94261950fe1c3afdf4087",
            "max": 85,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f3494c7e45740b8a69c9e914642ba98",
            "value": 85
          }
        },
        "e8f1b8251f96488098816e4ce426af40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e217f4b9e8944d2b93a530aff24eb77",
            "placeholder": "​",
            "style": "IPY_MODEL_a5f5a7be8bc74e829f4cf9ff6fd348c3",
            "value": " 85.0/85.0 [00:00&lt;00:00, 721B/s]"
          }
        },
        "9ef961f656484abaaa467a72166bb161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a1570957b654c0dba8bf813e5127413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b226af00cd574a36bbb80fbe1b68489a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5e92409b0b94261950fe1c3afdf4087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f3494c7e45740b8a69c9e914642ba98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e217f4b9e8944d2b93a530aff24eb77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5f5a7be8bc74e829f4cf9ff6fd348c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dc6ac32204743a3989839fb9e19e2c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a894e9d0fc84183bc49e98bd4fbd9ab",
              "IPY_MODEL_badc16ebe2d440cc969396b1508f1206",
              "IPY_MODEL_16863b15db764fe5ab804e26d83ea6b0"
            ],
            "layout": "IPY_MODEL_ac40374086b84966a08f81d9949e3d11"
          }
        },
        "8a894e9d0fc84183bc49e98bd4fbd9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7a56403be294da58dca66f3a14c8d79",
            "placeholder": "​",
            "style": "IPY_MODEL_48e010a2fcc34fa0b51fcc0b89f4c53e",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "badc16ebe2d440cc969396b1508f1206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4325969d95424ebcab14962f5b261a",
            "max": 1262009187,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47a79d10fdf74f649da885373ccafa92",
            "value": 1262009187
          }
        },
        "16863b15db764fe5ab804e26d83ea6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091898b193d74c7b9cd74e72d6f96773",
            "placeholder": "​",
            "style": "IPY_MODEL_524e6656a0104ec5900efa5b4a7c5591",
            "value": " 1.26G/1.26G [00:11&lt;00:00, 196MB/s]"
          }
        },
        "ac40374086b84966a08f81d9949e3d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7a56403be294da58dca66f3a14c8d79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48e010a2fcc34fa0b51fcc0b89f4c53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4325969d95424ebcab14962f5b261a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a79d10fdf74f649da885373ccafa92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "091898b193d74c7b9cd74e72d6f96773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "524e6656a0104ec5900efa5b4a7c5591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a80010b99fa48a6beb2a63aed62f223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d465536767a47bea8eb935ec1fd4063",
              "IPY_MODEL_af90df8fbe0a4e6199b40e1dbdf98cb5",
              "IPY_MODEL_838d99fc5b6e4a54b9417d726ff277af"
            ],
            "layout": "IPY_MODEL_4feebf0236bb4b72bc4f0dbe3a7855f4"
          }
        },
        "9d465536767a47bea8eb935ec1fd4063": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30ddf1b7d19b4354b893347e9807ccbb",
            "placeholder": "​",
            "style": "IPY_MODEL_77276f1505d34639819ab252bca7766f",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "af90df8fbe0a4e6199b40e1dbdf98cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f05298efefe442639852ca1b5167c78c",
            "max": 212,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d430714e5d84428b8e091d58c3d3311e",
            "value": 212
          }
        },
        "838d99fc5b6e4a54b9417d726ff277af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00843ef5e9bc47eca521d7f90f9bd419",
            "placeholder": "​",
            "style": "IPY_MODEL_5cf33e2f9c624e139609a625e0292993",
            "value": " 212/212 [00:00&lt;00:00, 4.53kB/s]"
          }
        },
        "4feebf0236bb4b72bc4f0dbe3a7855f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30ddf1b7d19b4354b893347e9807ccbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77276f1505d34639819ab252bca7766f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f05298efefe442639852ca1b5167c78c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d430714e5d84428b8e091d58c3d3311e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "00843ef5e9bc47eca521d7f90f9bd419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cf33e2f9c624e139609a625e0292993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47d00463c0c241018caa1ddc7860d29c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d00bb1751df44b9fbe7c32f7f227d517",
              "IPY_MODEL_f628f5301bf64d3cac309f8fde1e1780",
              "IPY_MODEL_4eba5381dae64be4ad738912e718692e"
            ],
            "layout": "IPY_MODEL_379bfb4fbdca41f78109f091a3f9dcbd"
          }
        },
        "d00bb1751df44b9fbe7c32f7f227d517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_533d6d2b79ca420eae0ae8da8bdbef57",
            "placeholder": "​",
            "style": "IPY_MODEL_f7af5ec3ec184e708a51034f69f27a3d",
            "value": "config.json: 100%"
          }
        },
        "f628f5301bf64d3cac309f8fde1e1780": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9bf1bf1837241619ebae6ef8256411a",
            "max": 1768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b418dbc7a4fd47a3b3cac100153b2cf9",
            "value": 1768
          }
        },
        "4eba5381dae64be4ad738912e718692e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd81c1a6068d496a980ef6989eb043aa",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a483c3173e4fa2839a888ffe6a1650",
            "value": " 1.77k/1.77k [00:00&lt;00:00, 54.1kB/s]"
          }
        },
        "379bfb4fbdca41f78109f091a3f9dcbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "533d6d2b79ca420eae0ae8da8bdbef57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7af5ec3ec184e708a51034f69f27a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9bf1bf1837241619ebae6ef8256411a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b418dbc7a4fd47a3b3cac100153b2cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd81c1a6068d496a980ef6989eb043aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a483c3173e4fa2839a888ffe6a1650": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namrata935/SandalTalk/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zVK133oU6JJ",
        "outputId": "58fb85b1-3f0b-4b46-8335-ea1d0bae8dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/800.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m798.7/800.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting triton>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=841a6bfdbd6cfd2ea981f6d833b9400cc39ffe0cf0c57568731ed1285a44fa1e\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: pydub, triton, ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20240930 pydub-0.25.1 tiktoken-0.8.0 triton-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai-whisper pydub ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0THUlvfVr0f",
        "outputId": "4e86bca1-be63-402d-87a8-28e6ba0d5ff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXMykRTwgE0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model(\"small\")  # Use \"medium\" or \"large\" for better accuracy but slower performance\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGKHQJTiXIrY",
        "outputId": "77888aaf-5c31-4342-8acd-6fde8a1decef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:18<00:00, 25.5MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the model\n",
        "model = whisper.load_model(\"small\")  # You can also use \"medium\" or \"large\" for better accuracy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL4AdSEBf7yy",
        "outputId": "578ec30c-820a-45d0-9bb8-3594c4f73172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "au5MxDLW9LKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Model loaded successfully:\", model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avU9LZCIf-oV",
        "outputId": "e73ebac5-3eab-430c-8c30-a6fba99f9d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully: Whisper(\n",
            "  (encoder): AudioEncoder(\n",
            "    (conv1): Conv1d(80, 768, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "    (conv2): Conv1d(768, 768, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "    (blocks): ModuleList(\n",
            "      (0-11): 12 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (decoder): TextDecoder(\n",
            "    (token_embedding): Embedding(51865, 768)\n",
            "    (blocks): ModuleList(\n",
            "      (0-11): 12 x ResidualAttentionBlock(\n",
            "        (attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (cross_attn): MultiHeadAttention(\n",
            "          (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (key): Linear(in_features=768, out_features=768, bias=False)\n",
            "          (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "          (out): Linear(in_features=768, out_features=768, bias=True)\n",
            "        )\n",
            "        (cross_attn_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU(approximate='none')\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "        (mlp_ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (ln): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Define paths\n",
        "input_path = \"/content/drive/MyDrive/audiocorpus\"  # Replace with the path to your folder\n",
        "output_csv = \"/content/drive/MyDrive/transcriptions.csv\"  # Path to save the transcription CSV\n",
        "\n",
        "# Create and write headers to the CSV file\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Filename\", \"Transcription\"])\n",
        "\n",
        "    # Loop through each .mp3 file and transcribe\n",
        "    for filename in os.listdir(input_path):\n",
        "        if filename.endswith(\".mp3\"):  # Only process .mp3 files\n",
        "            file_path = os.path.join(input_path, filename)\n",
        "            result = model.transcribe(file_path)  # Remove language=\"kn\"\n",
        "            transcription = result[\"text\"]\n",
        "            writer.writerow([filename, transcription])  # Save filename and transcription to CSV\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2njOrWWOgE6v",
        "outputId": "8a57533d-59b7-4c41-c17c-fa79abbb1265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-9-ca6004524284>\", line 17, in <cell line: 9>\n",
            "    result = model.transcribe(file_path)  # Remove language=\"kn\"\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 279, in transcribe\n",
            "    result: DecodingResult = decode_with_fallback(mel_segment)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\", line 195, in decode_with_fallback\n",
            "    decode_result = model.decode(segment, options)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\", line 824, in decode\n",
            "    result = DecodingTask(model, options).run(mel)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\", line 718, in run\n",
            "    audio_features: Tensor = self._get_audio_features(mel)  # encoder forward pass\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\", line 655, in _get_audio_features\n",
            "    audio_features = self.model.encoder(mel)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/model.py\", line 201, in forward\n",
            "    x = block(x)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/model.py\", line 170, in forward\n",
            "    x = x + self.mlp(self.mlp_ln(x))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\", line 250, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1736, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1747, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/whisper/model.py\", line 46, in forward\n",
            "    return F.linear(\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1620, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 829, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 878, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 397, in realpath\n",
            "    return abspath(path)\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 386, in abspath\n",
            "    return normpath(path)\n",
            "  File \"/usr/lib/python3.10/posixpath.py\", line 360, in normpath\n",
            "    comps = path.split(sep)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Check if CUDA is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA is available. Using GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available. Using CPU.\")\n",
        "\n",
        "# Optionally, you can check how much memory is available on the GPU\n",
        "if device.type == 'cuda':\n",
        "    print(\"Memory allocated:\", torch.cuda.memory_allocated(device) / 1024**3, \"GB\")\n",
        "    print(\"Memory cached:\", torch.cuda.memory_reserved(device) / 1024**3, \"GB\")\n"
      ],
      "metadata": {
        "id": "CXz-PQ3L9oBW",
        "outputId": "41ac0b2b-6915-4d45-ab37-5d7a0ad7da38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is not available. Using CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vayld6ouXIQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torchaudio\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXlyoea99FG",
        "outputId": "eb2c75d1-0e73-420a-ace6-74592f19277f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.10/dist-packages (from torchaudio) (2.5.0+cu121)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.0->torchaudio) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.0->torchaudio) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.0->torchaudio) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD23nkNx_oFJ",
        "outputId": "0ecafb2b-824b-4aee-a82d-ca27891e6676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torchaudio\n",
        "\n",
        "# Load the processor and model\n",
        "model_name = \"facebook/wav2vec2-large-960h\"  # You can choose other variants as well\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350,
          "referenced_widgets": [
            "d1d184c6610b40a1b2d8621c12860c42",
            "c2efcc7924c44333a440ee7c9c5f6936",
            "7c06f7e4d578430fbd4e6a00374d639b",
            "838866e74dc84a56b4aa62a0b6ecf2fc",
            "47fde11dd2914090958715a678736fa4",
            "0094cc03aa1e446eb569351c9ef849c3",
            "583c13d2f4034924b9b6f4078538328d",
            "df80ea617c6e4a248e3e80f63d47ec71",
            "309d2843ccbf4ab0b24fa53765971046",
            "88feb26cdffc48e5ae028992e7de3907",
            "969750d807814a2f8d4b5019d1a3538f",
            "d02168d183544029bc452aa6d77ed6fa",
            "41118369599846b78934840d7ec64a83",
            "d6f25dcbdc524a96a5a7da6ca5e7b17e",
            "3357ad4e4dde466ea77e34eb99424529",
            "c2b6944a94734448aaf7147661d9a810",
            "30623f74d5c54ba1b88eed1d28437cc1",
            "092aa43ed8e740b2af08f0280b7af57e",
            "9392dd13e155457eb6981d57151f1f89",
            "c6203b183b3e42dd9863928ae2b0e654",
            "d099577757214eb9b086d285828e7091",
            "cbf6162e2d824d69b73ebcfbf60ada14",
            "f159e349464349c9a20baf4f78c3409c",
            "ae27b2acb93b46e48a856f24413af77e",
            "a581b5e792454f60b8998f0cc5abf4fc",
            "52c1a27fae434170be870d4595197c44",
            "729b3e494a47433f8d162fafbb7039b4",
            "d5df899690be4645bffb477613a1fc9f",
            "0a839fb745fd447fb9a4e3e3bdac016a",
            "7321738e6fc1456db65a983b4a6a6837",
            "097a8210a11f4f50ae8583ce53f2d8d3",
            "e745f8185857400ca3b9ca098f8a98f7",
            "2d24d079910845d9b1e0e5ac12407b41",
            "bd3338d9bf8249e8a103e049b482b578",
            "7311fb3bc1484d65b9c51a52d4371ac1",
            "db04469e86a040de9569ffafee99009f",
            "73e9d59dd27b4894bc0b7c7d1435eb93",
            "1a5a7f3fa0f5472488fe51b99e6594e2",
            "4d8a318b0af743b6b13b66e875ab1d27",
            "5f2892befc904ee59a819dbdd96d9ca5",
            "858e79516bc44842b36718807649c544",
            "7a029b3296354ea2ae8c4548dad584e1",
            "f60b203f2d564885b02ba454ed052d79",
            "d1c43f9f659d4c829e92c3ea95ce5fcf",
            "ff0d76aa27954415ad099ca540148727",
            "2cf3f82412994332b09789f09a0d4a67",
            "f7529535dbde42868b377db6cd705ca3",
            "e8f1b8251f96488098816e4ce426af40",
            "9ef961f656484abaaa467a72166bb161",
            "0a1570957b654c0dba8bf813e5127413",
            "b226af00cd574a36bbb80fbe1b68489a",
            "b5e92409b0b94261950fe1c3afdf4087",
            "5f3494c7e45740b8a69c9e914642ba98",
            "6e217f4b9e8944d2b93a530aff24eb77",
            "a5f5a7be8bc74e829f4cf9ff6fd348c3",
            "1dc6ac32204743a3989839fb9e19e2c1",
            "8a894e9d0fc84183bc49e98bd4fbd9ab",
            "badc16ebe2d440cc969396b1508f1206",
            "16863b15db764fe5ab804e26d83ea6b0",
            "ac40374086b84966a08f81d9949e3d11",
            "c7a56403be294da58dca66f3a14c8d79",
            "48e010a2fcc34fa0b51fcc0b89f4c53e",
            "df4325969d95424ebcab14962f5b261a",
            "47a79d10fdf74f649da885373ccafa92",
            "091898b193d74c7b9cd74e72d6f96773",
            "524e6656a0104ec5900efa5b4a7c5591"
          ]
        },
        "id": "MdJUmPR7AY1O",
        "outputId": "0e599660-6fb4-4bd8-b7d1-dda138bfe697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1d184c6610b40a1b2d8621c12860c42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/163 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d02168d183544029bc452aa6d77ed6fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f159e349464349c9a20baf4f78c3409c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/291 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd3338d9bf8249e8a103e049b482b578"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff0d76aa27954415ad099ca540148727"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.26G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dc6ac32204743a3989839fb9e19e2c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/wav2vec2-large-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "import torchaudio\n",
        "\n",
        "input_folder = \"/content/drive/MyDrive/audiocorpus\"  # Replace with your folder path\n",
        "output_folder = \"/content/processed_audio\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "def process_audio(file_path, output_folder, target_sample_rate=16000, max_duration=60):\n",
        "    # Load .mp3 file and convert to .wav\n",
        "    audio = AudioSegment.from_mp3(file_path)\n",
        "\n",
        "    # Trim to one minute\n",
        "    audio = audio[:max_duration * 1000]\n",
        "\n",
        "    # Export as .wav\n",
        "    wav_path = os.path.join(output_folder, os.path.basename(file_path).replace(\".mp3\", \".wav\"))\n",
        "    audio.export(wav_path, format=\"wav\")\n",
        "\n",
        "    # Resample to 16,000 Hz using torchaudio\n",
        "    waveform, sample_rate = torchaudio.load(wav_path)\n",
        "    if sample_rate != target_sample_rate:\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)(waveform)\n",
        "        torchaudio.save(wav_path, waveform, sample_rate=target_sample_rate)\n",
        "\n",
        "    return wav_path\n",
        "\n",
        "# Process all files in the input folder\n",
        "processed_files = []\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.endswith(\".mp3\"):\n",
        "        file_path = os.path.join(input_folder, filename)\n",
        "        processed_file = process_audio(file_path, output_folder)\n",
        "        processed_files.append(processed_file)\n"
      ],
      "metadata": {
        "id": "ch5zpccnA7Am"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torchaudio\n",
        "import csv\n",
        "\n",
        "# Load the multilingual Wav2Vec 2.0 model and processor\n",
        "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
        "\n",
        "# Transcription function\n",
        "def transcribe_audio(file_path):\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # Ensure waveform is single channel\n",
        "    if waveform.ndim > 1:\n",
        "        waveform = waveform.mean(dim=0)\n",
        "\n",
        "    # Resample to 16kHz if necessary\n",
        "    if sample_rate != 16000:\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
        "\n",
        "    # Preprocess input\n",
        "    input_values = processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "\n",
        "    return transcription\n",
        "\n",
        "# Save transcriptions to CSV\n",
        "output_csv = \"/content/drive/MyDrive/transcriptions.csv\"\n",
        "\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Filename\", \"Transcription\"])\n",
        "\n",
        "    for file_path in processed_files:\n",
        "        transcription = transcribe_audio(file_path)\n",
        "        writer.writerow([os.path.basename(file_path), transcription])\n",
        "        print(f\"Transcribed {os.path.basename(file_path)}\")\n",
        "\n",
        "print(\"Transcriptions saved to\", output_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "id": "ecgtnqudDNz4",
        "outputId": "fd306ae0-1351-43d0-dd49-74627603b813"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:55: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arguments_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m_get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-ac401d77fbfb>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Load the multilingual Wav2Vec 2.0 model and processor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/wav2vec2-large-xlsr-53\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2FeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2CTCTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name, cache_dir=\"/content/huggingface_cache\")\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name, cache_dir=\"/content/huggingface_cache\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576,
          "referenced_widgets": [
            "7a80010b99fa48a6beb2a63aed62f223",
            "9d465536767a47bea8eb935ec1fd4063",
            "af90df8fbe0a4e6199b40e1dbdf98cb5",
            "838d99fc5b6e4a54b9417d726ff277af",
            "4feebf0236bb4b72bc4f0dbe3a7855f4",
            "30ddf1b7d19b4354b893347e9807ccbb",
            "77276f1505d34639819ab252bca7766f",
            "f05298efefe442639852ca1b5167c78c",
            "d430714e5d84428b8e091d58c3d3311e",
            "00843ef5e9bc47eca521d7f90f9bd419",
            "5cf33e2f9c624e139609a625e0292993",
            "47d00463c0c241018caa1ddc7860d29c",
            "d00bb1751df44b9fbe7c32f7f227d517",
            "f628f5301bf64d3cac309f8fde1e1780",
            "4eba5381dae64be4ad738912e718692e",
            "379bfb4fbdca41f78109f091a3f9dcbd",
            "533d6d2b79ca420eae0ae8da8bdbef57",
            "f7af5ec3ec184e708a51034f69f27a3d",
            "b9bf1bf1837241619ebae6ef8256411a",
            "b418dbc7a4fd47a3b3cac100153b2cf9",
            "dd81c1a6068d496a980ef6989eb043aa",
            "c5a483c3173e4fa2839a888ffe6a1650"
          ]
        },
        "id": "VqVFT4QnErXH",
        "outputId": "0a3a95bb-283a-46ec-d101-acc9b1c75dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/212 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a80010b99fa48a6beb2a63aed62f223"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.77k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47d00463c0c241018caa1ddc7860d29c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arguments_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m_get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-5cc3edddc53b>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/wav2vec2-large-xlsr-53\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/huggingface_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/huggingface_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2FeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2CTCTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U transformers\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "id": "d5kgr2XLE6ro",
        "outputId": "3c4086fa-f169-4330-8b16-dd1d61eab2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.1/44.1 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed tokenizers-0.20.3 transformers-4.46.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "f60b68b6c9ec4ba49accf0cbb54a42c8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torchaudio\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Mount Google Drive to access your audio files and save the CSV\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your Google Drive folder path containing .mp3 files and where to save CSV file\n",
        "audio_folder = '/content/processed_audio'  # Update with your folder path\n",
        "output_csv = '/content/drive/MyDrive/kannada_transcriptions.csv'\n",
        "\n",
        "# Load the Wav2Vec2 model and processor for multilingual transcription\n",
        "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
        "\n",
        "# Function to transcribe audio\n",
        "def transcribe_audio(file_path):\n",
        "    waveform, sample_rate = torchaudio.load(file_path)\n",
        "\n",
        "    # Check if the audio sample rate is 16000 Hz, resample if needed\n",
        "    if sample_rate != 16000:\n",
        "        waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)\n",
        "\n",
        "    # Convert stereo to mono if necessary\n",
        "    if waveform.ndim > 1:\n",
        "        waveform = waveform.mean(dim=0)  # Convert to mono\n",
        "\n",
        "    # Process the audio and prepare for model input\n",
        "    input_values = processor(waveform, sampling_rate=16000, return_tensors=\"pt\").input_values\n",
        "\n",
        "    # Perform the transcription\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_values).logits\n",
        "    predicted_ids = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    # Decode the predicted IDs to text (Kannada transcription)\n",
        "    transcription = processor.decode(predicted_ids[0])\n",
        "    return transcription\n",
        "\n",
        "# Process and transcribe each file, saving the output to CSV\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Filename\", \"Transcription\"])\n",
        "\n",
        "    for file_name in os.listdir(audio_folder):\n",
        "        if file_name.endswith(\".mp3\") or file_name.endswith(\".wav\"):  # Only process audio files\n",
        "            file_path = os.path.join(audio_folder, file_name)\n",
        "            try:\n",
        "                transcription = transcribe_audio(file_path)\n",
        "                writer.writerow([file_name, transcription])\n",
        "                print(f\"Transcribed {file_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_name}: {e}\")\n",
        "\n",
        "print(f\"Transcriptions saved to {output_csv}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        },
        "id": "oPSLLL6gFJA8",
        "outputId": "7fba9d26-0bc6-46bc-f2ee-1b13110168a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:61: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arguments_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m_get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2198\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-acb8e4883c96>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Load the Wav2Vec2 model and processor for multilingual transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"facebook/wav2vec2-large-xlsr-53\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2FeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2CTCTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2195\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2198\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
        "import torchaudio\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# Mount Google Drive to access your audio files and save the CSV\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set your Google Drive folder path containing .mp3 files and where to save CSV file\n",
        "audio_folder = '/content/processed_audio'  # Update with your folder path\n",
        "output_csv = '/content/drive/MyDrive/kannada_transcriptions.csv'\n",
        "\n",
        "# Load the Wav2Vec2 model and processor for multilingual transcription\n",
        "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
        "\n",
        "# Specify cache directory to ensure tokenizer files are downloaded there\n",
        "cache_dir = \"/content/huggingface_cache\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(model_name, cache_dir=cache_dir)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(model_name, cache_dir=cache_dir)\n",
        "\n",
        "# ... (rest of your code remains the same)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "Jns8eGhnGdFy",
        "outputId": "90258059-23a6-4da4-82b3-6f7a6cb8f8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py:61: FutureWarning: Loading a tokenizer inside Wav2Vec2Processor from a config that does not include a `tokenizer_class` attribute is deprecated and will be removed in v5. Please add `'tokenizer_class': 'Wav2Vec2CTCTokenizer'` attribute to either your `config.json` or `tokenizer_config.json` file to suppress this warning: \n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, **kwargs)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_arguments_from_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m         \u001b[0mprocessor_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_processor_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m_get_arguments_from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattribute_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer_class_py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2198\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cbfdeb345a1f>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Specify cache directory to ensure tokenizer files are downloaded there\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/huggingface_cache\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2Processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/processing_wav2vec2.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2FeatureExtractor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2CTCTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   2195\u001b[0m         \u001b[0;31m# loaded directly from the GGUF file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_file_name\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull_file_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresolved_vocab_files\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgguf_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m             raise EnvironmentError(\n\u001b[0m\u001b[1;32m   2198\u001b[0m                 \u001b[0;34mf\"Can't load tokenizer for '{pretrained_model_name_or_path}'. If you were trying to load it from \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m                 \u001b[0;34m\"'https://huggingface.co/models', make sure you don't have a local directory with the same name. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Can't load tokenizer for 'facebook/wav2vec2-large-xlsr-53'. If you were trying to load it from 'https://huggingface.co/models', make sure you don't have a local directory with the same name. Otherwise, make sure 'facebook/wav2vec2-large-xlsr-53' is the correct path to a directory containing all relevant files for a Wav2Vec2CTCTokenizer tokenizer."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vosk\n",
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEfRF2byG0_N",
        "outputId": "e6b8e2a4-559e-47e9-c6d3-eac9ba5ac49f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vosk\n",
            "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from vosk) (1.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vosk) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vosk) (4.66.6)\n",
            "Collecting srt (from vosk)\n",
            "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting websockets (from vosk)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->vosk) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vosk) (2024.8.30)\n",
            "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: srt\n",
            "  Building wheel for srt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22428 sha256=c0365f4a5cc77672712dfc0addc42e5c1c8b46cbb88dc789cb2a5c0e1dd18bad\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/31/a1/18e1e7e8bfdafd19e6803d7eb919b563dd11de380e4304e332\n",
            "Successfully built srt\n",
            "Installing collected packages: websockets, srt, vosk\n",
            "Successfully installed srt-3.5.3 vosk-0.3.45 websockets-13.1\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://alphacephei.com/vosk/models/vosk-model-kn-0.22.zip\n",
        "!unzip vosk-model-kn-0.22.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vfLl9sFG2b-",
        "outputId": "dd9a59e8-45a1-42bc-aa74-c34d8bf2e6a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 10:11:38--  https://alphacephei.com/vosk/models/vosk-model-kn-0.22.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-11-07 10:11:39 ERROR 404: Not Found.\n",
            "\n",
            "unzip:  cannot find or open vosk-model-kn-0.22.zip, vosk-model-kn-0.22.zip.zip or vosk-model-kn-0.22.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O vosk-model-kn-0.22.zip https://alphacephei.com/vosk/models/vosk-model-kn-0.22.zip\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUVIXEWyHIXX",
        "outputId": "217e815e-0434-4f74-9beb-558027df7810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-07 10:12:36--  https://alphacephei.com/vosk/models/vosk-model-kn-0.22.zip\n",
            "Resolving alphacephei.com (alphacephei.com)... 188.40.21.16, 2a01:4f8:13a:279f::2\n",
            "Connecting to alphacephei.com (alphacephei.com)|188.40.21.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-11-07 10:12:37 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai-whisper\n",
        "!sudo apt update && sudo apt install -y ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxXD6TXOG8Ih",
        "outputId": "035b40cb-3cf5-4ba6-91e4-5776d25c805c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,611 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,449 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,319 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,397 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,241 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,672 kB]\n",
            "Fetched 25.7 MB in 4s (6,414 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "51 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import csv\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "JJIanYF9Irjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Whisper model (e.g., \"small\" or \"medium\" for better accuracy)\n",
        "model = whisper.load_model(\"small\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruX-My7FIvw6",
        "outputId": "3f075514-9bf9-47dd-9e16-61a83994aeee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:07<00:00, 66.3MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your audio files in Google Drive\n",
        "audio_folder = \"/content/drive/MyDrive/audiocorpus\"  # Replace with your folder path\n",
        "\n",
        "# Output CSV file path\n",
        "output_csv = \"/content/drive/MyDrive/Whisper_Transcriptions.csv\"\n"
      ],
      "metadata": {
        "id": "3NbosJDDIz2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and open the CSV file for writing\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Filename\", \"Transcription\"])  # Header row\n",
        "\n",
        "    # Loop through each audio file in the directory\n",
        "    for audio_file in tqdm(os.listdir(audio_folder)):\n",
        "        if audio_file.endswith(\".mp3\"):  # Process only .wav files\n",
        "            file_path = os.path.join(audio_folder, audio_file)\n",
        "\n",
        "            # Perform transcription\n",
        "            result = model.transcribe(file_path, language=\"kn\")  # \"kn\" for Kannada\n",
        "            transcription = result[\"text\"]\n",
        "\n",
        "            # Write the filename and transcription to CSV\n",
        "            writer.writerow([audio_file, transcription])\n",
        "            print(f\"Transcribed: {audio_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "w6sPoYW4I603",
        "outputId": "ae1a43d5-864f-4115-d918-bf333c57a59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/71 [02:30<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-8ba4505107af>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Perform transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kn\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# \"kn\" for Kannada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mSDPA_AVAILABLE\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_sdpa\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             a = scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mn_ctx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bqMWY9iKPMR",
        "outputId": "0756d0fa-52dd-42d9-9685-be70e848a003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOujJQnsKeRI",
        "outputId": "86d6e671-067e-4cbc-f5a8-c705da5fc0d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "0mZZ00CwKg3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input folder containing original audio files in .mp3 format\n",
        "input_folder = \"/content/drive/MyDrive/audiocorpus\"  # Replace with your folder path\n",
        "\n",
        "# Output folder to save processed .wav files\n",
        "output_folder = \"/content/drive/MyDrive/ProcessedAudio\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "gC6NUlRZKkUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Duration for each segment in milliseconds (1 minute = 60,000 milliseconds)\n",
        "segment_duration_ms = 60 * 1000\n",
        "\n",
        "# Loop through each .mp3 file in the input folder\n",
        "for audio_file in tqdm(os.listdir(input_folder)):\n",
        "    if audio_file.endswith(\".mp3\"):  # Process only .mp3 files\n",
        "        # Load the audio file\n",
        "        file_path = os.path.join(input_folder, audio_file)\n",
        "        audio = AudioSegment.from_mp3(file_path)\n",
        "\n",
        "        # Calculate the number of segments\n",
        "        num_segments = len(audio) // segment_duration_ms + int(len(audio) % segment_duration_ms > 0)\n",
        "\n",
        "        # Split and export each segment\n",
        "        for i in range(num_segments):\n",
        "            start_time = i * segment_duration_ms\n",
        "            end_time = start_time + segment_duration_ms\n",
        "            segment = audio[start_time:end_time]\n",
        "\n",
        "            # Set sample rate to 16kHz\n",
        "            segment = segment.set_frame_rate(16000)\n",
        "\n",
        "            # Export the segment as .wav file\n",
        "            output_file = os.path.join(output_folder, f\"{os.path.splitext(audio_file)[0]}_part{i+1}.wav\")\n",
        "            segment.export(output_file, format=\"wav\")\n",
        "\n",
        "            print(f\"Exported {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im97coEiKpUM",
        "outputId": "8dae21ba-b316-437e-e1ef-4d9e6de6ff3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/71 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part22.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part23.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part24.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 1/71 [00:09<10:54,  9.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part25.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_1_part26.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 2/71 [00:10<05:15,  4.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_146_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_146_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_146_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_146_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_146_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 3/71 [00:11<03:03,  2.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_148_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_148_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part17.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 4/71 [00:15<03:46,  3.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_156_part19.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 5/71 [00:15<02:29,  2.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_112_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 6/71 [00:19<03:02,  2.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_144_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|▉         | 7/71 [00:20<02:11,  2.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_107_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 11%|█▏        | 8/71 [00:23<02:30,  2.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_158_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part22.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part23.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part24.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part25.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part26.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part27.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part28.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part29.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part30.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part31.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part32.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part33.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part34.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part35.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part36.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part37.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part38.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part39.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part40.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part41.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part42.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part43.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part44.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part45.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part46.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part47.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part48.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part49.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part50.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part51.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part52.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part53.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part54.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part55.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part56.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part57.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part58.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part59.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part60.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part61.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part62.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part63.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part64.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part65.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part66.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part67.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part68.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part69.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 13%|█▎        | 9/71 [00:42<07:49,  7.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part70.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part71.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_159_part72.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part22.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part23.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 14%|█▍        | 10/71 [00:51<08:09,  8.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part24.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_169_part25.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 15%|█▌        | 11/71 [00:52<05:56,  5.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_168_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_168_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_168_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 12/71 [00:53<04:25,  4.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_167_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_167_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_167_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part22.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 18%|█▊        | 13/71 [00:59<04:45,  4.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part23.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part24.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_179_part25.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|█▉        | 14/71 [01:01<03:46,  3.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_173_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 21%|██        | 15/71 [01:05<03:42,  3.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_174_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 23%|██▎       | 16/71 [01:09<03:40,  4.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_175_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part19.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 24%|██▍       | 17/71 [01:14<03:54,  4.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_176_part22.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 18/71 [01:14<02:47,  3.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_181_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 27%|██▋       | 19/71 [01:17<02:34,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 28%|██▊       | 20/71 [01:20<02:25,  2.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_171_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|██▉       | 21/71 [01:21<02:08,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_184_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_184_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_184_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_184_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 31%|███       | 22/71 [01:24<01:59,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_229_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 32%|███▏      | 23/71 [01:24<01:33,  1.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_249_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_249_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_249_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_249_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 34%|███▍      | 24/71 [01:26<01:26,  1.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_230_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 35%|███▌      | 25/71 [01:29<01:36,  2.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_197_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 37%|███▋      | 26/71 [01:31<01:44,  2.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_215_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 38%|███▊      | 27/71 [01:35<01:53,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_242_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 39%|███▉      | 28/71 [01:36<01:32,  2.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_223_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_223_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_223_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 41%|████      | 29/71 [01:36<01:10,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_257_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 30/71 [01:37<00:54,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_23_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_23_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 44%|████▎     | 31/71 [01:39<00:57,  1.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_239_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 45%|████▌     | 32/71 [01:40<00:51,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_211_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_211_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_211_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_211_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 46%|████▋     | 33/71 [01:41<00:50,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_191_part6.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 48%|████▊     | 34/71 [01:42<00:43,  1.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_2_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_2_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_2_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_2_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 49%|████▉     | 35/71 [01:43<00:47,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_200_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 51%|█████     | 36/71 [01:46<00:58,  1.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_283_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 52%|█████▏    | 37/71 [01:49<01:15,  2.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_280_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part14.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 54%|█████▎    | 38/71 [01:54<01:40,  3.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_282_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part17.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 55%|█████▍    | 39/71 [01:59<01:51,  3.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_279_part22.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part17.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 56%|█████▋    | 40/71 [02:04<02:03,  4.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_286_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part15.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 41/71 [02:09<02:11,  4.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_278_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 59%|█████▉    | 42/71 [02:12<01:48,  3.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_284_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 61%|██████    | 43/71 [02:14<01:35,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_296_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part18.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 62%|██████▏   | 44/71 [02:21<02:00,  4.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_298_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 63%|██████▎   | 45/71 [02:22<01:31,  3.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_297_part6.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 65%|██████▍   | 46/71 [02:23<01:04,  2.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_291_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 66%|██████▌   | 47/71 [02:25<00:59,  2.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_305_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 68%|██████▊   | 48/71 [02:27<00:56,  2.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_295_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 69%|██████▉   | 49/71 [02:30<00:52,  2.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_303_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 50/71 [02:32<00:52,  2.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_304_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 72%|███████▏  | 51/71 [02:35<00:47,  2.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_299_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part22.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 73%|███████▎  | 52/71 [02:41<01:07,  3.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_287_part23.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_306_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_306_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_306_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▍  | 53/71 [02:42<00:51,  2.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_306_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 76%|███████▌  | 54/71 [02:43<00:36,  2.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_294_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_294_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 77%|███████▋  | 55/71 [02:43<00:26,  1.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_63_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 79%|███████▉  | 56/71 [02:44<00:19,  1.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_53_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_53_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part19.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 57/71 [02:49<00:35,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_42_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 82%|████████▏ | 58/71 [02:53<00:40,  3.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_49_part12.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 59/71 [02:55<00:30,  2.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_46_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_46_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_46_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_46_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_46_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 85%|████████▍ | 60/71 [02:58<00:29,  2.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_33_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 86%|████████▌ | 61/71 [03:00<00:24,  2.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_36_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 87%|████████▋ | 62/71 [03:02<00:21,  2.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_45_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 89%|████████▊ | 63/71 [03:06<00:23,  2.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_6_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_52_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_52_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_52_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_52_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 64/71 [03:08<00:17,  2.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_52_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 65/71 [03:08<00:12,  2.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_41_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_41_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_41_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 93%|█████████▎| 66/71 [03:11<00:11,  2.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_35_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 94%|█████████▍| 67/71 [03:14<00:09,  2.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_43_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 96%|█████████▌| 68/71 [03:15<00:05,  1.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_99_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_99_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_99_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 97%|█████████▋| 69/71 [03:16<00:03,  1.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_98_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part18.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part21.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part22.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 99%|█████████▊| 70/71 [03:23<00:03,  3.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part23.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_9_part24.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part1.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part2.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part3.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part4.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part5.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part6.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part7.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part8.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part9.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part10.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part11.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part12.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part13.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part14.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part15.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part16.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part17.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part18.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 71/71 [03:28<00:00,  2.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part19.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part20.wav\n",
            "Exported /content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_89_part21.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install indic-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1PZg3LVLqfW",
        "outputId": "5a8e91b9-ac75-4d24-de3f-1daa934397a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement indic-whisper (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for indic-whisper\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper\n",
        "!pip install pydub\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmDaF4x1LvcM",
        "outputId": "1ac9af2e-e2ec-4b26-b4fe-0758e490d0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import whisper\n",
        "from tqdm import tqdm\n",
        "from pydub import AudioSegment\n"
      ],
      "metadata": {
        "id": "dczxNyTVL5oZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "\n",
        "# Load the Whisper model (you can choose \"small\", \"medium\", or \"large\")\n",
        "model = whisper.load_model(\"small\")  # Or \"medium\" / \"large\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nI6Hf5joL9e9",
        "outputId": "bed53344-35dc-432e-be1c-0716ba9a5e77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Input folder where the processed .wav files are stored\n",
        "input_folder = \"/content/drive/MyDrive/ProcessedAudio\"  # Replace with your folder path\n",
        "\n",
        "# Output CSV file to save transcriptions\n",
        "output_csv = \"/content/drive/MyDrive/Transcriptions.csv\"\n"
      ],
      "metadata": {
        "id": "Eo0a0YYpMCyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the CSV file for writing the transcription results\n",
        "with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow([\"Filename\", \"Transcription\"])  # Write the header row\n",
        "\n",
        "    # Loop through each .wav file in the input folder\n",
        "    for audio_file in tqdm(os.listdir(input_folder)):\n",
        "        if audio_file.endswith(\".wav\"):  # Process only .wav files\n",
        "            file_path = os.path.join(input_folder, audio_file)\n",
        "\n",
        "            # Transcribe the audio using Whisper\n",
        "            result = model.transcribe(file_path, language=\"kn\")  # \"kn\" is the language code for Kannada\n",
        "\n",
        "            # Get the transcription text\n",
        "            transcription = result[\"text\"]\n",
        "\n",
        "            # Write the filename and transcription to the CSV file\n",
        "            writer.writerow([audio_file, transcription])\n",
        "            print(f\"Transcribed: {audio_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y7vH8S0eMG9m",
        "outputId": "860ab327-a3b5-4244-9116-ce9f20a872be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/756 [00:59<12:31:39, 59.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 2/756 [01:29<8:47:23, 41.97s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 3/756 [01:59<7:40:14, 36.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 4/756 [02:17<6:06:33, 29.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 5/756 [03:25<9:02:25, 43.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 6/756 [03:54<7:57:48, 38.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part6.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 7/756 [04:38<8:23:50, 40.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 8/756 [05:07<7:37:16, 36.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 9/756 [05:54<8:15:04, 39.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 10/756 [06:50<9:16:20, 44.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|▏         | 11/756 [07:44<9:52:17, 47.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 12/756 [08:12<8:37:26, 41.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part12.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 13/756 [08:37<7:32:21, 36.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part13.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 14/756 [09:34<8:49:38, 42.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part14.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 15/756 [10:15<8:40:15, 42.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part15.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 16/756 [11:07<9:18:00, 45.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part16.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 17/756 [11:33<8:04:54, 39.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part17.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  2%|▏         | 18/756 [12:22<8:41:15, 42.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part18.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 19/756 [13:18<9:30:15, 46.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part19.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 20/756 [13:20<6:47:20, 33.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part20.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 21/756 [13:59<7:06:47, 34.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part21.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 22/756 [14:02<5:10:44, 25.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part22.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 23/756 [15:01<7:12:27, 35.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part23.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 24/756 [15:54<8:15:23, 40.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part24.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 25/756 [16:21<7:25:51, 36.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part25.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  3%|▎         | 26/756 [16:25<5:25:41, 26.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_1_part26.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 27/756 [17:13<6:44:01, 33.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_146_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▎         | 28/756 [17:22<5:13:41, 25.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_146_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 29/756 [18:16<6:54:35, 34.22s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_146_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 30/756 [19:10<8:07:20, 40.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_146_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 31/756 [19:14<5:54:30, 29.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_146_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 32/756 [19:43<5:51:31, 29.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_148_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 33/756 [20:03<5:19:06, 26.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_148_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  4%|▍         | 34/756 [20:11<4:13:32, 21.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 35/756 [20:20<3:26:51, 17.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 36/756 [20:27<2:52:11, 14.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▍         | 37/756 [20:56<3:42:46, 18.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 38/756 [21:24<4:16:34, 21.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 39/756 [21:47<4:24:05, 22.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part6.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 40/756 [21:55<3:32:59, 17.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  5%|▌         | 41/756 [22:25<4:13:39, 21.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 42/756 [22:32<3:24:11, 17.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 43/756 [22:41<2:53:30, 14.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 44/756 [23:22<4:27:15, 22.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 45/756 [24:02<5:30:17, 27.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part12.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 46/756 [24:10<4:19:52, 21.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part13.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▌         | 47/756 [24:19<3:32:02, 17.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part14.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 48/756 [24:26<2:54:09, 14.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part15.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  6%|▋         | 49/756 [24:35<2:32:05, 12.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part16.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 50/756 [24:42<2:12:07, 11.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part17.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 51/756 [24:51<2:02:11, 10.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part18.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 52/756 [24:54<1:38:39,  8.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_156_part19.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 53/756 [25:11<2:08:53, 11.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_112_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 54/756 [25:20<1:59:49, 10.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 55/756 [25:28<1:51:55,  9.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  7%|▋         | 56/756 [26:07<3:34:43, 18.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 57/756 [26:15<2:59:26, 15.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 58/756 [26:23<2:33:05, 13.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 59/756 [27:12<4:36:38, 23.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part6.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 60/756 [28:04<6:16:03, 32.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part7.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 61/756 [28:45<6:44:21, 34.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part8.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 62/756 [28:53<5:09:10, 26.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part9.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 63/756 [29:01<4:05:41, 21.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part10.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  8%|▊         | 64/756 [29:05<3:04:41, 16.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_144_part11.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 65/756 [29:09<2:22:34, 12.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_107_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▊         | 66/756 [29:52<4:06:39, 21.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_158_part1.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 67/756 [30:45<5:56:34, 31.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_158_part2.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 68/756 [30:53<4:38:25, 24.28s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_158_part3.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 69/756 [31:01<3:41:03, 19.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_158_part4.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 70/756 [31:10<3:03:10, 16.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed: SandalWoodNewsStories_158_part5.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  9%|▉         | 70/756 [31:35<5:09:32, 27.07s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-aabb68c406b1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m# Transcribe the audio using Whisper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kn\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# \"kn\" is the language code for Kannada\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Get the transcription text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mdecode_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_reset_since\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDecodingResult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_with_fallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_segment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py\u001b[0m in \u001b[0;36mdecode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mdecode_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mneeds_fallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecodingTask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msingle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0;31m# call the main sampling loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_logprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_speech_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_main_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0;31m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36m_main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/decoding.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, tokens, audio_features)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcleanup_caching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, kv_cache)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mkv_cache\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     ):\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_attn_ln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkv_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, xa, mask, kv_cache)\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqkv_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/whisper/model.py\u001b[0m in \u001b[0;36mqkv_attention\u001b[0;34m(self, q, k, v, mask)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     def qkv_attention(\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     ) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "from pydub import AudioSegment\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/processed_audio\"\n",
        "# Initialize recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Function to transcribe audio using Google Speech API\n",
        "def transcribe_audio(file_path):\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)  # Record audio from the file\n",
        "        try:\n",
        "            # Transcribe using Google's API for Kannada language (kn-IN)\n",
        "            transcription = recognizer.recognize_google(audio, language='kn-IN')\n",
        "            return transcription  # Return the transcribed text\n",
        "        except sr.RequestError as e:\n",
        "            return f\"API request error: {e}\"\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Unable to recognize speech\"\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Function to split audio into chunks (default chunk size is 30 seconds)\n",
        "def split_audio(file_path, chunk_length_ms=30000):  # Default is 30 seconds\n",
        "    audio = AudioSegment.from_wav(file_path)\n",
        "    chunks = [audio[i:i + chunk_length_ms] for i in range(0, len(audio), chunk_length_ms)]\n",
        "    return chunks\n",
        "\n",
        "# Function to transcribe chunks and store the results\n",
        "def transcribe_chunks_and_save_csv(chunks, output_csv='transcriptions.csv'):\n",
        "    # List to hold transcription data for saving into CSV\n",
        "    transcription_data = []\n",
        "\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_file = f\"chunk_{i}.wav\"\n",
        "        chunk.export(chunk_file, format=\"wav\")  # Save each chunk as a separate file\n",
        "        transcription = transcribe_audio(chunk_file)  # Transcribe each chunk\n",
        "\n",
        "        # Append the transcription and chunk file name to the data list\n",
        "        transcription_data.append([chunk_file, transcription])\n",
        "\n",
        "    # Create a DataFrame from the transcription data\n",
        "    df = pd.DataFrame(transcription_data, columns=['Audio File', 'Transcription'])\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Transcriptions saved to {output_csv}\")\n",
        "\n",
        "# Example usage\n",
        "audio_file = 'denoised_audio.wav'  # Replace with your actual file path\n",
        "chunks = split_audio(audio_file)  # Split audio into chunks\n",
        "transcribe_chunks_and_save_csv(chunks)  # Transcribe and save to CSV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "_c9fKw2RUMyU",
        "outputId": "1d412371-10f5-4992-e9f7-a90d47bda64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydub'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4a0b38db9ddc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/processed_audio\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the folder where your audio files are stored in Google Drive\n",
        "audio_folder = '/content/drive/MyDrive/ProcessedAudio'\n",
        "\n",
        "# List all audio files (assuming they are in WAV format)\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav') ]\n",
        "\n",
        "# Print the list of files to confirm\n",
        "print(audio_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTWqp6vXWn-Z",
        "outputId": "53915c3b-d987-40ad-bf80-8912d64197c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['SandalWoodNewsStories_1_part1.wav', 'SandalWoodNewsStories_1_part2.wav', 'SandalWoodNewsStories_1_part3.wav', 'SandalWoodNewsStories_1_part4.wav', 'SandalWoodNewsStories_1_part5.wav', 'SandalWoodNewsStories_1_part6.wav', 'SandalWoodNewsStories_1_part7.wav', 'SandalWoodNewsStories_1_part8.wav', 'SandalWoodNewsStories_1_part9.wav', 'SandalWoodNewsStories_1_part10.wav', 'SandalWoodNewsStories_1_part11.wav', 'SandalWoodNewsStories_1_part12.wav', 'SandalWoodNewsStories_1_part13.wav', 'SandalWoodNewsStories_1_part14.wav', 'SandalWoodNewsStories_1_part15.wav', 'SandalWoodNewsStories_1_part16.wav', 'SandalWoodNewsStories_1_part17.wav', 'SandalWoodNewsStories_1_part18.wav', 'SandalWoodNewsStories_1_part19.wav', 'SandalWoodNewsStories_1_part20.wav', 'SandalWoodNewsStories_1_part21.wav', 'SandalWoodNewsStories_1_part22.wav', 'SandalWoodNewsStories_1_part23.wav', 'SandalWoodNewsStories_1_part24.wav', 'SandalWoodNewsStories_1_part25.wav', 'SandalWoodNewsStories_1_part26.wav', 'SandalWoodNewsStories_146_part1.wav', 'SandalWoodNewsStories_146_part2.wav', 'SandalWoodNewsStories_146_part3.wav', 'SandalWoodNewsStories_146_part4.wav', 'SandalWoodNewsStories_146_part5.wav', 'SandalWoodNewsStories_148_part1.wav', 'SandalWoodNewsStories_148_part2.wav', 'SandalWoodNewsStories_156_part1.wav', 'SandalWoodNewsStories_156_part2.wav', 'SandalWoodNewsStories_156_part3.wav', 'SandalWoodNewsStories_156_part4.wav', 'SandalWoodNewsStories_156_part5.wav', 'SandalWoodNewsStories_156_part6.wav', 'SandalWoodNewsStories_156_part7.wav', 'SandalWoodNewsStories_156_part8.wav', 'SandalWoodNewsStories_156_part9.wav', 'SandalWoodNewsStories_156_part10.wav', 'SandalWoodNewsStories_156_part11.wav', 'SandalWoodNewsStories_156_part12.wav', 'SandalWoodNewsStories_156_part13.wav', 'SandalWoodNewsStories_156_part14.wav', 'SandalWoodNewsStories_156_part15.wav', 'SandalWoodNewsStories_156_part16.wav', 'SandalWoodNewsStories_156_part17.wav', 'SandalWoodNewsStories_156_part18.wav', 'SandalWoodNewsStories_156_part19.wav', 'SandalWoodNewsStories_112_part1.wav', 'SandalWoodNewsStories_144_part1.wav', 'SandalWoodNewsStories_144_part2.wav', 'SandalWoodNewsStories_144_part3.wav', 'SandalWoodNewsStories_144_part4.wav', 'SandalWoodNewsStories_144_part5.wav', 'SandalWoodNewsStories_144_part6.wav', 'SandalWoodNewsStories_144_part7.wav', 'SandalWoodNewsStories_144_part8.wav', 'SandalWoodNewsStories_144_part9.wav', 'SandalWoodNewsStories_144_part10.wav', 'SandalWoodNewsStories_144_part11.wav', 'SandalWoodNewsStories_107_part1.wav', 'SandalWoodNewsStories_158_part1.wav', 'SandalWoodNewsStories_158_part2.wav', 'SandalWoodNewsStories_158_part3.wav', 'SandalWoodNewsStories_158_part4.wav', 'SandalWoodNewsStories_158_part5.wav', 'SandalWoodNewsStories_158_part6.wav', 'SandalWoodNewsStories_158_part7.wav', 'SandalWoodNewsStories_158_part8.wav', 'SandalWoodNewsStories_158_part9.wav', 'SandalWoodNewsStories_159_part1.wav', 'SandalWoodNewsStories_159_part2.wav', 'SandalWoodNewsStories_159_part3.wav', 'SandalWoodNewsStories_159_part4.wav', 'SandalWoodNewsStories_159_part5.wav', 'SandalWoodNewsStories_159_part6.wav', 'SandalWoodNewsStories_159_part7.wav', 'SandalWoodNewsStories_159_part8.wav', 'SandalWoodNewsStories_159_part9.wav', 'SandalWoodNewsStories_159_part10.wav', 'SandalWoodNewsStories_159_part11.wav', 'SandalWoodNewsStories_159_part12.wav', 'SandalWoodNewsStories_159_part13.wav', 'SandalWoodNewsStories_159_part14.wav', 'SandalWoodNewsStories_159_part15.wav', 'SandalWoodNewsStories_159_part16.wav', 'SandalWoodNewsStories_159_part17.wav', 'SandalWoodNewsStories_159_part18.wav', 'SandalWoodNewsStories_159_part19.wav', 'SandalWoodNewsStories_159_part20.wav', 'SandalWoodNewsStories_159_part21.wav', 'SandalWoodNewsStories_159_part22.wav', 'SandalWoodNewsStories_159_part23.wav', 'SandalWoodNewsStories_159_part24.wav', 'SandalWoodNewsStories_159_part25.wav', 'SandalWoodNewsStories_159_part26.wav', 'SandalWoodNewsStories_159_part27.wav', 'SandalWoodNewsStories_159_part28.wav', 'SandalWoodNewsStories_159_part29.wav', 'SandalWoodNewsStories_159_part30.wav', 'SandalWoodNewsStories_159_part31.wav', 'SandalWoodNewsStories_159_part32.wav', 'SandalWoodNewsStories_159_part33.wav', 'SandalWoodNewsStories_159_part34.wav', 'SandalWoodNewsStories_159_part35.wav', 'SandalWoodNewsStories_159_part36.wav', 'SandalWoodNewsStories_159_part37.wav', 'SandalWoodNewsStories_159_part38.wav', 'SandalWoodNewsStories_159_part39.wav', 'SandalWoodNewsStories_159_part40.wav', 'SandalWoodNewsStories_159_part41.wav', 'SandalWoodNewsStories_159_part42.wav', 'SandalWoodNewsStories_159_part43.wav', 'SandalWoodNewsStories_159_part44.wav', 'SandalWoodNewsStories_159_part45.wav', 'SandalWoodNewsStories_159_part46.wav', 'SandalWoodNewsStories_159_part47.wav', 'SandalWoodNewsStories_159_part48.wav', 'SandalWoodNewsStories_159_part49.wav', 'SandalWoodNewsStories_159_part50.wav', 'SandalWoodNewsStories_159_part51.wav', 'SandalWoodNewsStories_159_part52.wav', 'SandalWoodNewsStories_159_part53.wav', 'SandalWoodNewsStories_159_part54.wav', 'SandalWoodNewsStories_159_part55.wav', 'SandalWoodNewsStories_159_part56.wav', 'SandalWoodNewsStories_159_part57.wav', 'SandalWoodNewsStories_159_part58.wav', 'SandalWoodNewsStories_159_part59.wav', 'SandalWoodNewsStories_159_part60.wav', 'SandalWoodNewsStories_159_part61.wav', 'SandalWoodNewsStories_159_part62.wav', 'SandalWoodNewsStories_159_part63.wav', 'SandalWoodNewsStories_159_part64.wav', 'SandalWoodNewsStories_159_part65.wav', 'SandalWoodNewsStories_159_part66.wav', 'SandalWoodNewsStories_159_part67.wav', 'SandalWoodNewsStories_159_part68.wav', 'SandalWoodNewsStories_159_part69.wav', 'SandalWoodNewsStories_159_part70.wav', 'SandalWoodNewsStories_159_part71.wav', 'SandalWoodNewsStories_159_part72.wav', 'SandalWoodNewsStories_169_part1.wav', 'SandalWoodNewsStories_169_part2.wav', 'SandalWoodNewsStories_169_part3.wav', 'SandalWoodNewsStories_169_part4.wav', 'SandalWoodNewsStories_169_part5.wav', 'SandalWoodNewsStories_169_part6.wav', 'SandalWoodNewsStories_169_part7.wav', 'SandalWoodNewsStories_169_part8.wav', 'SandalWoodNewsStories_169_part9.wav', 'SandalWoodNewsStories_169_part10.wav', 'SandalWoodNewsStories_169_part11.wav', 'SandalWoodNewsStories_169_part12.wav', 'SandalWoodNewsStories_169_part13.wav', 'SandalWoodNewsStories_169_part14.wav', 'SandalWoodNewsStories_169_part15.wav', 'SandalWoodNewsStories_169_part16.wav', 'SandalWoodNewsStories_169_part17.wav', 'SandalWoodNewsStories_169_part18.wav', 'SandalWoodNewsStories_169_part19.wav', 'SandalWoodNewsStories_169_part20.wav', 'SandalWoodNewsStories_169_part21.wav', 'SandalWoodNewsStories_169_part22.wav', 'SandalWoodNewsStories_169_part23.wav', 'SandalWoodNewsStories_169_part24.wav', 'SandalWoodNewsStories_169_part25.wav', 'SandalWoodNewsStories_168_part1.wav', 'SandalWoodNewsStories_168_part2.wav', 'SandalWoodNewsStories_168_part3.wav', 'SandalWoodNewsStories_167_part1.wav', 'SandalWoodNewsStories_167_part2.wav', 'SandalWoodNewsStories_167_part3.wav', 'SandalWoodNewsStories_179_part1.wav', 'SandalWoodNewsStories_179_part2.wav', 'SandalWoodNewsStories_179_part3.wav', 'SandalWoodNewsStories_179_part4.wav', 'SandalWoodNewsStories_179_part5.wav', 'SandalWoodNewsStories_179_part6.wav', 'SandalWoodNewsStories_179_part7.wav', 'SandalWoodNewsStories_179_part8.wav', 'SandalWoodNewsStories_179_part9.wav', 'SandalWoodNewsStories_179_part10.wav', 'SandalWoodNewsStories_179_part11.wav', 'SandalWoodNewsStories_179_part12.wav', 'SandalWoodNewsStories_179_part13.wav', 'SandalWoodNewsStories_179_part14.wav', 'SandalWoodNewsStories_179_part15.wav', 'SandalWoodNewsStories_179_part16.wav', 'SandalWoodNewsStories_179_part17.wav', 'SandalWoodNewsStories_179_part18.wav', 'SandalWoodNewsStories_179_part19.wav', 'SandalWoodNewsStories_179_part20.wav', 'SandalWoodNewsStories_179_part21.wav', 'SandalWoodNewsStories_179_part22.wav', 'SandalWoodNewsStories_179_part23.wav', 'SandalWoodNewsStories_179_part24.wav', 'SandalWoodNewsStories_179_part25.wav', 'SandalWoodNewsStories_173_part1.wav', 'SandalWoodNewsStories_173_part2.wav', 'SandalWoodNewsStories_173_part3.wav', 'SandalWoodNewsStories_173_part4.wav', 'SandalWoodNewsStories_173_part5.wav', 'SandalWoodNewsStories_173_part6.wav', 'SandalWoodNewsStories_173_part7.wav', 'SandalWoodNewsStories_173_part8.wav', 'SandalWoodNewsStories_173_part9.wav', 'SandalWoodNewsStories_174_part1.wav', 'SandalWoodNewsStories_174_part2.wav', 'SandalWoodNewsStories_174_part3.wav', 'SandalWoodNewsStories_174_part4.wav', 'SandalWoodNewsStories_174_part5.wav', 'SandalWoodNewsStories_174_part6.wav', 'SandalWoodNewsStories_174_part7.wav', 'SandalWoodNewsStories_174_part8.wav', 'SandalWoodNewsStories_174_part9.wav', 'SandalWoodNewsStories_174_part10.wav', 'SandalWoodNewsStories_174_part11.wav', 'SandalWoodNewsStories_174_part12.wav', 'SandalWoodNewsStories_175_part1.wav', 'SandalWoodNewsStories_175_part2.wav', 'SandalWoodNewsStories_175_part3.wav', 'SandalWoodNewsStories_175_part4.wav', 'SandalWoodNewsStories_175_part5.wav', 'SandalWoodNewsStories_175_part6.wav', 'SandalWoodNewsStories_175_part7.wav', 'SandalWoodNewsStories_175_part8.wav', 'SandalWoodNewsStories_175_part9.wav', 'SandalWoodNewsStories_175_part10.wav', 'SandalWoodNewsStories_175_part11.wav', 'SandalWoodNewsStories_175_part12.wav', 'SandalWoodNewsStories_175_part13.wav', 'SandalWoodNewsStories_176_part1.wav', 'SandalWoodNewsStories_176_part2.wav', 'SandalWoodNewsStories_176_part3.wav', 'SandalWoodNewsStories_176_part4.wav', 'SandalWoodNewsStories_176_part5.wav', 'SandalWoodNewsStories_176_part6.wav', 'SandalWoodNewsStories_176_part7.wav', 'SandalWoodNewsStories_176_part8.wav', 'SandalWoodNewsStories_176_part9.wav', 'SandalWoodNewsStories_176_part10.wav', 'SandalWoodNewsStories_176_part11.wav', 'SandalWoodNewsStories_176_part12.wav', 'SandalWoodNewsStories_176_part13.wav', 'SandalWoodNewsStories_176_part14.wav', 'SandalWoodNewsStories_176_part15.wav', 'SandalWoodNewsStories_176_part16.wav', 'SandalWoodNewsStories_176_part17.wav', 'SandalWoodNewsStories_176_part18.wav', 'SandalWoodNewsStories_176_part19.wav', 'SandalWoodNewsStories_176_part20.wav', 'SandalWoodNewsStories_176_part21.wav', 'SandalWoodNewsStories_176_part22.wav', 'SandalWoodNewsStories_181_part1.wav', 'SandalWoodNewsStories_172_part1.wav', 'SandalWoodNewsStories_172_part2.wav', 'SandalWoodNewsStories_172_part3.wav', 'SandalWoodNewsStories_172_part4.wav', 'SandalWoodNewsStories_172_part5.wav', 'SandalWoodNewsStories_172_part6.wav', 'SandalWoodNewsStories_172_part7.wav', 'SandalWoodNewsStories_172_part8.wav', 'SandalWoodNewsStories_172_part9.wav', 'SandalWoodNewsStories_172_part10.wav', 'SandalWoodNewsStories_172_part11.wav', 'SandalWoodNewsStories_171_part1.wav', 'SandalWoodNewsStories_171_part2.wav', 'SandalWoodNewsStories_171_part3.wav', 'SandalWoodNewsStories_171_part4.wav', 'SandalWoodNewsStories_171_part5.wav', 'SandalWoodNewsStories_171_part6.wav', 'SandalWoodNewsStories_171_part7.wav', 'SandalWoodNewsStories_171_part8.wav', 'SandalWoodNewsStories_171_part9.wav', 'SandalWoodNewsStories_171_part10.wav', 'SandalWoodNewsStories_184_part1.wav', 'SandalWoodNewsStories_184_part2.wav', 'SandalWoodNewsStories_184_part3.wav', 'SandalWoodNewsStories_184_part4.wav', 'SandalWoodNewsStories_229_part1.wav', 'SandalWoodNewsStories_229_part2.wav', 'SandalWoodNewsStories_229_part3.wav', 'SandalWoodNewsStories_229_part4.wav', 'SandalWoodNewsStories_229_part5.wav', 'SandalWoodNewsStories_229_part6.wav', 'SandalWoodNewsStories_229_part7.wav', 'SandalWoodNewsStories_229_part8.wav', 'SandalWoodNewsStories_229_part9.wav', 'SandalWoodNewsStories_249_part1.wav', 'SandalWoodNewsStories_249_part2.wav', 'SandalWoodNewsStories_249_part3.wav', 'SandalWoodNewsStories_249_part4.wav', 'SandalWoodNewsStories_230_part1.wav', 'SandalWoodNewsStories_230_part2.wav', 'SandalWoodNewsStories_230_part3.wav', 'SandalWoodNewsStories_230_part4.wav', 'SandalWoodNewsStories_230_part5.wav', 'SandalWoodNewsStories_230_part6.wav', 'SandalWoodNewsStories_197_part1.wav', 'SandalWoodNewsStories_197_part2.wav', 'SandalWoodNewsStories_197_part3.wav', 'SandalWoodNewsStories_197_part4.wav', 'SandalWoodNewsStories_197_part5.wav', 'SandalWoodNewsStories_197_part6.wav', 'SandalWoodNewsStories_197_part7.wav', 'SandalWoodNewsStories_197_part8.wav', 'SandalWoodNewsStories_197_part9.wav', 'SandalWoodNewsStories_197_part10.wav', 'SandalWoodNewsStories_197_part11.wav', 'SandalWoodNewsStories_197_part12.wav', 'SandalWoodNewsStories_215_part1.wav', 'SandalWoodNewsStories_215_part2.wav', 'SandalWoodNewsStories_215_part3.wav', 'SandalWoodNewsStories_215_part4.wav', 'SandalWoodNewsStories_215_part5.wav', 'SandalWoodNewsStories_215_part6.wav', 'SandalWoodNewsStories_215_part7.wav', 'SandalWoodNewsStories_215_part8.wav', 'SandalWoodNewsStories_215_part9.wav', 'SandalWoodNewsStories_215_part10.wav', 'SandalWoodNewsStories_215_part11.wav', 'SandalWoodNewsStories_242_part1.wav', 'SandalWoodNewsStories_242_part2.wav', 'SandalWoodNewsStories_242_part3.wav', 'SandalWoodNewsStories_242_part4.wav', 'SandalWoodNewsStories_242_part5.wav', 'SandalWoodNewsStories_242_part6.wav', 'SandalWoodNewsStories_242_part7.wav', 'SandalWoodNewsStories_242_part8.wav', 'SandalWoodNewsStories_242_part9.wav', 'SandalWoodNewsStories_242_part10.wav', 'SandalWoodNewsStories_242_part11.wav', 'SandalWoodNewsStories_223_part1.wav', 'SandalWoodNewsStories_223_part2.wav', 'SandalWoodNewsStories_223_part3.wav', 'SandalWoodNewsStories_257_part1.wav', 'SandalWoodNewsStories_23_part1.wav', 'SandalWoodNewsStories_23_part2.wav', 'SandalWoodNewsStories_239_part1.wav', 'SandalWoodNewsStories_239_part2.wav', 'SandalWoodNewsStories_239_part3.wav', 'SandalWoodNewsStories_239_part4.wav', 'SandalWoodNewsStories_239_part5.wav', 'SandalWoodNewsStories_239_part6.wav', 'SandalWoodNewsStories_239_part7.wav', 'SandalWoodNewsStories_211_part1.wav', 'SandalWoodNewsStories_211_part2.wav', 'SandalWoodNewsStories_211_part3.wav', 'SandalWoodNewsStories_211_part4.wav', 'SandalWoodNewsStories_191_part1.wav', 'SandalWoodNewsStories_191_part2.wav', 'SandalWoodNewsStories_191_part3.wav', 'SandalWoodNewsStories_191_part4.wav', 'SandalWoodNewsStories_191_part5.wav', 'SandalWoodNewsStories_191_part6.wav', 'SandalWoodNewsStories_2_part1.wav', 'SandalWoodNewsStories_2_part2.wav', 'SandalWoodNewsStories_2_part3.wav', 'SandalWoodNewsStories_2_part4.wav', 'SandalWoodNewsStories_200_part1.wav', 'SandalWoodNewsStories_200_part2.wav', 'SandalWoodNewsStories_200_part3.wav', 'SandalWoodNewsStories_200_part4.wav', 'SandalWoodNewsStories_200_part5.wav', 'SandalWoodNewsStories_200_part6.wav', 'SandalWoodNewsStories_200_part7.wav', 'SandalWoodNewsStories_283_part1.wav', 'SandalWoodNewsStories_283_part2.wav', 'SandalWoodNewsStories_283_part3.wav', 'SandalWoodNewsStories_283_part4.wav', 'SandalWoodNewsStories_283_part5.wav', 'SandalWoodNewsStories_283_part6.wav', 'SandalWoodNewsStories_283_part7.wav', 'SandalWoodNewsStories_283_part8.wav', 'SandalWoodNewsStories_283_part9.wav', 'SandalWoodNewsStories_283_part10.wav', 'SandalWoodNewsStories_283_part11.wav', 'SandalWoodNewsStories_280_part1.wav', 'SandalWoodNewsStories_280_part2.wav', 'SandalWoodNewsStories_280_part3.wav', 'SandalWoodNewsStories_280_part4.wav', 'SandalWoodNewsStories_280_part5.wav', 'SandalWoodNewsStories_280_part6.wav', 'SandalWoodNewsStories_280_part7.wav', 'SandalWoodNewsStories_280_part8.wav', 'SandalWoodNewsStories_280_part9.wav', 'SandalWoodNewsStories_280_part10.wav', 'SandalWoodNewsStories_280_part11.wav', 'SandalWoodNewsStories_280_part12.wav', 'SandalWoodNewsStories_280_part13.wav', 'SandalWoodNewsStories_282_part1.wav', 'SandalWoodNewsStories_282_part2.wav', 'SandalWoodNewsStories_282_part3.wav', 'SandalWoodNewsStories_282_part4.wav', 'SandalWoodNewsStories_282_part5.wav', 'SandalWoodNewsStories_282_part6.wav', 'SandalWoodNewsStories_282_part7.wav', 'SandalWoodNewsStories_282_part8.wav', 'SandalWoodNewsStories_282_part9.wav', 'SandalWoodNewsStories_282_part10.wav', 'SandalWoodNewsStories_282_part11.wav', 'SandalWoodNewsStories_282_part12.wav', 'SandalWoodNewsStories_282_part13.wav', 'SandalWoodNewsStories_282_part14.wav', 'SandalWoodNewsStories_282_part15.wav', 'SandalWoodNewsStories_282_part16.wav', 'SandalWoodNewsStories_282_part17.wav', 'SandalWoodNewsStories_282_part18.wav', 'SandalWoodNewsStories_282_part19.wav', 'SandalWoodNewsStories_279_part1.wav', 'SandalWoodNewsStories_279_part2.wav', 'SandalWoodNewsStories_279_part3.wav', 'SandalWoodNewsStories_279_part4.wav', 'SandalWoodNewsStories_279_part5.wav', 'SandalWoodNewsStories_279_part6.wav', 'SandalWoodNewsStories_279_part7.wav', 'SandalWoodNewsStories_279_part8.wav', 'SandalWoodNewsStories_279_part9.wav', 'SandalWoodNewsStories_279_part10.wav', 'SandalWoodNewsStories_279_part11.wav', 'SandalWoodNewsStories_279_part12.wav', 'SandalWoodNewsStories_279_part13.wav', 'SandalWoodNewsStories_279_part14.wav', 'SandalWoodNewsStories_279_part15.wav', 'SandalWoodNewsStories_279_part16.wav', 'SandalWoodNewsStories_279_part17.wav', 'SandalWoodNewsStories_279_part18.wav', 'SandalWoodNewsStories_279_part19.wav', 'SandalWoodNewsStories_279_part20.wav', 'SandalWoodNewsStories_279_part21.wav', 'SandalWoodNewsStories_279_part22.wav', 'SandalWoodNewsStories_286_part1.wav', 'SandalWoodNewsStories_286_part2.wav', 'SandalWoodNewsStories_286_part3.wav', 'SandalWoodNewsStories_286_part4.wav', 'SandalWoodNewsStories_286_part5.wav', 'SandalWoodNewsStories_286_part6.wav', 'SandalWoodNewsStories_286_part7.wav', 'SandalWoodNewsStories_286_part8.wav', 'SandalWoodNewsStories_286_part9.wav', 'SandalWoodNewsStories_286_part10.wav', 'SandalWoodNewsStories_286_part11.wav', 'SandalWoodNewsStories_286_part12.wav', 'SandalWoodNewsStories_286_part13.wav', 'SandalWoodNewsStories_286_part14.wav', 'SandalWoodNewsStories_286_part15.wav', 'SandalWoodNewsStories_286_part16.wav', 'SandalWoodNewsStories_286_part17.wav', 'SandalWoodNewsStories_286_part18.wav', 'SandalWoodNewsStories_286_part19.wav', 'SandalWoodNewsStories_286_part20.wav', 'SandalWoodNewsStories_278_part1.wav', 'SandalWoodNewsStories_278_part2.wav', 'SandalWoodNewsStories_278_part3.wav', 'SandalWoodNewsStories_278_part4.wav', 'SandalWoodNewsStories_278_part5.wav', 'SandalWoodNewsStories_278_part6.wav', 'SandalWoodNewsStories_278_part7.wav', 'SandalWoodNewsStories_278_part8.wav', 'SandalWoodNewsStories_278_part9.wav', 'SandalWoodNewsStories_278_part10.wav', 'SandalWoodNewsStories_278_part11.wav', 'SandalWoodNewsStories_278_part12.wav', 'SandalWoodNewsStories_278_part13.wav', 'SandalWoodNewsStories_278_part14.wav', 'SandalWoodNewsStories_278_part15.wav', 'SandalWoodNewsStories_278_part16.wav', 'SandalWoodNewsStories_278_part17.wav', 'SandalWoodNewsStories_278_part18.wav', 'SandalWoodNewsStories_284_part1.wav', 'SandalWoodNewsStories_284_part2.wav', 'SandalWoodNewsStories_284_part3.wav', 'SandalWoodNewsStories_284_part4.wav', 'SandalWoodNewsStories_284_part5.wav', 'SandalWoodNewsStories_284_part6.wav', 'SandalWoodNewsStories_284_part7.wav', 'SandalWoodNewsStories_284_part8.wav', 'SandalWoodNewsStories_284_part9.wav', 'SandalWoodNewsStories_296_part1.wav', 'SandalWoodNewsStories_296_part2.wav', 'SandalWoodNewsStories_296_part3.wav', 'SandalWoodNewsStories_296_part4.wav', 'SandalWoodNewsStories_296_part5.wav', 'SandalWoodNewsStories_296_part6.wav', 'SandalWoodNewsStories_296_part7.wav', 'SandalWoodNewsStories_296_part8.wav', 'SandalWoodNewsStories_296_part9.wav', 'SandalWoodNewsStories_298_part1.wav', 'SandalWoodNewsStories_298_part2.wav', 'SandalWoodNewsStories_298_part3.wav', 'SandalWoodNewsStories_298_part4.wav', 'SandalWoodNewsStories_298_part5.wav', 'SandalWoodNewsStories_298_part6.wav', 'SandalWoodNewsStories_298_part7.wav', 'SandalWoodNewsStories_298_part8.wav', 'SandalWoodNewsStories_298_part9.wav', 'SandalWoodNewsStories_298_part10.wav', 'SandalWoodNewsStories_298_part11.wav', 'SandalWoodNewsStories_298_part12.wav', 'SandalWoodNewsStories_298_part13.wav', 'SandalWoodNewsStories_298_part14.wav', 'SandalWoodNewsStories_298_part15.wav', 'SandalWoodNewsStories_298_part16.wav', 'SandalWoodNewsStories_298_part17.wav', 'SandalWoodNewsStories_298_part18.wav', 'SandalWoodNewsStories_298_part19.wav', 'SandalWoodNewsStories_298_part20.wav', 'SandalWoodNewsStories_298_part21.wav', 'SandalWoodNewsStories_297_part1.wav', 'SandalWoodNewsStories_297_part2.wav', 'SandalWoodNewsStories_297_part3.wav', 'SandalWoodNewsStories_297_part4.wav', 'SandalWoodNewsStories_297_part5.wav', 'SandalWoodNewsStories_297_part6.wav', 'SandalWoodNewsStories_291_part1.wav', 'SandalWoodNewsStories_305_part1.wav', 'SandalWoodNewsStories_305_part2.wav', 'SandalWoodNewsStories_305_part3.wav', 'SandalWoodNewsStories_305_part4.wav', 'SandalWoodNewsStories_305_part5.wav', 'SandalWoodNewsStories_305_part6.wav', 'SandalWoodNewsStories_305_part7.wav', 'SandalWoodNewsStories_305_part8.wav', 'SandalWoodNewsStories_305_part9.wav', 'SandalWoodNewsStories_305_part10.wav', 'SandalWoodNewsStories_305_part11.wav', 'SandalWoodNewsStories_295_part1.wav', 'SandalWoodNewsStories_295_part2.wav', 'SandalWoodNewsStories_295_part3.wav', 'SandalWoodNewsStories_295_part4.wav', 'SandalWoodNewsStories_295_part5.wav', 'SandalWoodNewsStories_295_part6.wav', 'SandalWoodNewsStories_295_part7.wav', 'SandalWoodNewsStories_295_part8.wav', 'SandalWoodNewsStories_295_part9.wav', 'SandalWoodNewsStories_303_part1.wav', 'SandalWoodNewsStories_303_part2.wav', 'SandalWoodNewsStories_303_part3.wav', 'SandalWoodNewsStories_303_part4.wav', 'SandalWoodNewsStories_303_part5.wav', 'SandalWoodNewsStories_303_part6.wav', 'SandalWoodNewsStories_303_part7.wav', 'SandalWoodNewsStories_303_part8.wav', 'SandalWoodNewsStories_303_part9.wav', 'SandalWoodNewsStories_304_part1.wav', 'SandalWoodNewsStories_304_part2.wav', 'SandalWoodNewsStories_304_part3.wav', 'SandalWoodNewsStories_304_part4.wav', 'SandalWoodNewsStories_304_part5.wav', 'SandalWoodNewsStories_304_part6.wav', 'SandalWoodNewsStories_304_part7.wav', 'SandalWoodNewsStories_299_part1.wav', 'SandalWoodNewsStories_299_part2.wav', 'SandalWoodNewsStories_299_part3.wav', 'SandalWoodNewsStories_299_part4.wav', 'SandalWoodNewsStories_299_part5.wav', 'SandalWoodNewsStories_299_part6.wav', 'SandalWoodNewsStories_287_part1.wav', 'SandalWoodNewsStories_287_part2.wav', 'SandalWoodNewsStories_287_part3.wav', 'SandalWoodNewsStories_287_part4.wav', 'SandalWoodNewsStories_287_part5.wav', 'SandalWoodNewsStories_287_part6.wav', 'SandalWoodNewsStories_287_part7.wav', 'SandalWoodNewsStories_287_part8.wav', 'SandalWoodNewsStories_287_part9.wav', 'SandalWoodNewsStories_287_part10.wav', 'SandalWoodNewsStories_287_part11.wav', 'SandalWoodNewsStories_287_part12.wav', 'SandalWoodNewsStories_287_part13.wav', 'SandalWoodNewsStories_287_part14.wav', 'SandalWoodNewsStories_287_part15.wav', 'SandalWoodNewsStories_287_part16.wav', 'SandalWoodNewsStories_287_part17.wav', 'SandalWoodNewsStories_287_part18.wav', 'SandalWoodNewsStories_287_part19.wav', 'SandalWoodNewsStories_287_part20.wav', 'SandalWoodNewsStories_287_part21.wav', 'SandalWoodNewsStories_287_part22.wav', 'SandalWoodNewsStories_287_part23.wav', 'SandalWoodNewsStories_306_part1.wav', 'SandalWoodNewsStories_306_part2.wav', 'SandalWoodNewsStories_306_part3.wav', 'SandalWoodNewsStories_306_part4.wav', 'SandalWoodNewsStories_294_part1.wav', 'SandalWoodNewsStories_294_part2.wav', 'SandalWoodNewsStories_63_part1.wav', 'SandalWoodNewsStories_53_part1.wav', 'SandalWoodNewsStories_53_part2.wav', 'SandalWoodNewsStories_42_part1.wav', 'SandalWoodNewsStories_42_part2.wav', 'SandalWoodNewsStories_42_part3.wav', 'SandalWoodNewsStories_42_part4.wav', 'SandalWoodNewsStories_42_part5.wav', 'SandalWoodNewsStories_42_part6.wav', 'SandalWoodNewsStories_42_part7.wav', 'SandalWoodNewsStories_42_part8.wav', 'SandalWoodNewsStories_42_part9.wav', 'SandalWoodNewsStories_42_part10.wav', 'SandalWoodNewsStories_42_part11.wav', 'SandalWoodNewsStories_42_part12.wav', 'SandalWoodNewsStories_42_part13.wav', 'SandalWoodNewsStories_42_part14.wav', 'SandalWoodNewsStories_42_part15.wav', 'SandalWoodNewsStories_42_part16.wav', 'SandalWoodNewsStories_42_part17.wav', 'SandalWoodNewsStories_42_part18.wav', 'SandalWoodNewsStories_42_part19.wav', 'SandalWoodNewsStories_42_part20.wav', 'SandalWoodNewsStories_42_part21.wav', 'SandalWoodNewsStories_49_part1.wav', 'SandalWoodNewsStories_49_part2.wav', 'SandalWoodNewsStories_49_part3.wav', 'SandalWoodNewsStories_49_part4.wav', 'SandalWoodNewsStories_49_part5.wav', 'SandalWoodNewsStories_49_part6.wav', 'SandalWoodNewsStories_49_part7.wav', 'SandalWoodNewsStories_49_part8.wav', 'SandalWoodNewsStories_49_part9.wav', 'SandalWoodNewsStories_49_part10.wav', 'SandalWoodNewsStories_49_part11.wav', 'SandalWoodNewsStories_49_part12.wav', 'SandalWoodNewsStories_46_part1.wav', 'SandalWoodNewsStories_46_part2.wav', 'SandalWoodNewsStories_46_part3.wav', 'SandalWoodNewsStories_46_part4.wav', 'SandalWoodNewsStories_46_part5.wav', 'SandalWoodNewsStories_33_part1.wav', 'SandalWoodNewsStories_33_part2.wav', 'SandalWoodNewsStories_33_part3.wav', 'SandalWoodNewsStories_33_part4.wav', 'SandalWoodNewsStories_33_part5.wav', 'SandalWoodNewsStories_33_part6.wav', 'SandalWoodNewsStories_33_part7.wav', 'SandalWoodNewsStories_33_part8.wav', 'SandalWoodNewsStories_33_part9.wav', 'SandalWoodNewsStories_33_part10.wav', 'SandalWoodNewsStories_33_part11.wav', 'SandalWoodNewsStories_33_part12.wav', 'SandalWoodNewsStories_33_part13.wav', 'SandalWoodNewsStories_36_part1.wav', 'SandalWoodNewsStories_36_part2.wav', 'SandalWoodNewsStories_36_part3.wav', 'SandalWoodNewsStories_36_part4.wav', 'SandalWoodNewsStories_36_part5.wav', 'SandalWoodNewsStories_36_part6.wav', 'SandalWoodNewsStories_36_part7.wav', 'SandalWoodNewsStories_36_part8.wav', 'SandalWoodNewsStories_45_part1.wav', 'SandalWoodNewsStories_45_part2.wav', 'SandalWoodNewsStories_45_part3.wav', 'SandalWoodNewsStories_45_part4.wav', 'SandalWoodNewsStories_45_part5.wav', 'SandalWoodNewsStories_45_part6.wav', 'SandalWoodNewsStories_45_part7.wav', 'SandalWoodNewsStories_45_part8.wav', 'SandalWoodNewsStories_45_part9.wav', 'SandalWoodNewsStories_6_part1.wav', 'SandalWoodNewsStories_6_part2.wav', 'SandalWoodNewsStories_6_part3.wav', 'SandalWoodNewsStories_6_part4.wav', 'SandalWoodNewsStories_6_part5.wav', 'SandalWoodNewsStories_6_part6.wav', 'SandalWoodNewsStories_6_part7.wav', 'SandalWoodNewsStories_6_part8.wav', 'SandalWoodNewsStories_6_part9.wav', 'SandalWoodNewsStories_6_part10.wav', 'SandalWoodNewsStories_6_part11.wav', 'SandalWoodNewsStories_52_part1.wav', 'SandalWoodNewsStories_52_part2.wav', 'SandalWoodNewsStories_52_part3.wav', 'SandalWoodNewsStories_52_part4.wav', 'SandalWoodNewsStories_52_part5.wav', 'SandalWoodNewsStories_41_part1.wav', 'SandalWoodNewsStories_41_part2.wav', 'SandalWoodNewsStories_41_part3.wav', 'SandalWoodNewsStories_35_part1.wav', 'SandalWoodNewsStories_35_part2.wav', 'SandalWoodNewsStories_35_part3.wav', 'SandalWoodNewsStories_35_part4.wav', 'SandalWoodNewsStories_35_part5.wav', 'SandalWoodNewsStories_35_part6.wav', 'SandalWoodNewsStories_35_part7.wav', 'SandalWoodNewsStories_35_part8.wav', 'SandalWoodNewsStories_35_part9.wav', 'SandalWoodNewsStories_43_part1.wav', 'SandalWoodNewsStories_43_part2.wav', 'SandalWoodNewsStories_43_part3.wav', 'SandalWoodNewsStories_43_part4.wav', 'SandalWoodNewsStories_43_part5.wav', 'SandalWoodNewsStories_43_part6.wav', 'SandalWoodNewsStories_43_part7.wav', 'SandalWoodNewsStories_43_part8.wav', 'SandalWoodNewsStories_43_part9.wav', 'SandalWoodNewsStories_43_part10.wav', 'SandalWoodNewsStories_43_part11.wav', 'SandalWoodNewsStories_99_part1.wav', 'SandalWoodNewsStories_99_part2.wav', 'SandalWoodNewsStories_99_part3.wav', 'SandalWoodNewsStories_98_part1.wav', 'SandalWoodNewsStories_98_part2.wav', 'SandalWoodNewsStories_98_part3.wav', 'SandalWoodNewsStories_98_part4.wav', 'SandalWoodNewsStories_98_part5.wav', 'SandalWoodNewsStories_98_part6.wav', 'SandalWoodNewsStories_98_part7.wav', 'SandalWoodNewsStories_9_part1.wav', 'SandalWoodNewsStories_9_part2.wav', 'SandalWoodNewsStories_9_part3.wav', 'SandalWoodNewsStories_9_part4.wav', 'SandalWoodNewsStories_9_part5.wav', 'SandalWoodNewsStories_9_part6.wav', 'SandalWoodNewsStories_9_part7.wav', 'SandalWoodNewsStories_9_part8.wav', 'SandalWoodNewsStories_9_part9.wav', 'SandalWoodNewsStories_9_part10.wav', 'SandalWoodNewsStories_9_part11.wav', 'SandalWoodNewsStories_9_part12.wav', 'SandalWoodNewsStories_9_part13.wav', 'SandalWoodNewsStories_9_part14.wav', 'SandalWoodNewsStories_9_part15.wav', 'SandalWoodNewsStories_9_part16.wav', 'SandalWoodNewsStories_9_part17.wav', 'SandalWoodNewsStories_9_part18.wav', 'SandalWoodNewsStories_9_part19.wav', 'SandalWoodNewsStories_9_part20.wav', 'SandalWoodNewsStories_9_part21.wav', 'SandalWoodNewsStories_9_part22.wav', 'SandalWoodNewsStories_9_part23.wav', 'SandalWoodNewsStories_9_part24.wav', 'SandalWoodNewsStories_89_part1.wav', 'SandalWoodNewsStories_89_part2.wav', 'SandalWoodNewsStories_89_part3.wav', 'SandalWoodNewsStories_89_part4.wav', 'SandalWoodNewsStories_89_part5.wav', 'SandalWoodNewsStories_89_part6.wav', 'SandalWoodNewsStories_89_part7.wav', 'SandalWoodNewsStories_89_part8.wav', 'SandalWoodNewsStories_89_part9.wav', 'SandalWoodNewsStories_89_part10.wav', 'SandalWoodNewsStories_89_part11.wav', 'SandalWoodNewsStories_89_part12.wav', 'SandalWoodNewsStories_89_part13.wav', 'SandalWoodNewsStories_89_part14.wav', 'SandalWoodNewsStories_89_part15.wav', 'SandalWoodNewsStories_89_part16.wav', 'SandalWoodNewsStories_89_part17.wav', 'SandalWoodNewsStories_89_part18.wav', 'SandalWoodNewsStories_89_part19.wav', 'SandalWoodNewsStories_89_part20.wav', 'SandalWoodNewsStories_89_part21.wav']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Function to transcribe audio\n",
        "def transcribe_audio(file_path):\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)  # Record audio from the file\n",
        "        try:\n",
        "            # Transcribe using Google API\n",
        "            transcription = recognizer.recognize_google(audio, language='kn-IN')\n",
        "            return transcription\n",
        "        except sr.RequestError as e:\n",
        "            return f\"API request error: {e}\"\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Unable to recognize speech\"\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Set up folders for audio and CSV output\n",
        "audio_folder = '/content/drive/MyDrive/ProcessedAudio'\n",
        "output_csv_path = '/content/drive/MyDrive/audiocorpus/trans.csv'\n",
        "\n",
        "# Initialize an empty list to store all transcriptions\n",
        "all_transcriptions = []\n",
        "\n",
        "# Loop through all audio files in the folder\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav')]\n",
        "for audio_file in audio_files:\n",
        "    audio_path = os.path.join(audio_folder, audio_file)\n",
        "\n",
        "    # Transcribe the audio\n",
        "    transcription = transcribe_audio(audio_path)\n",
        "\n",
        "    # Print each transcription\n",
        "    print(f\"Transcription for {audio_file}: {transcription}\")\n",
        "\n",
        "    # Append the file name and transcription to the list\n",
        "    all_transcriptions.append({'File Name': audio_file, 'Transcription': transcription})\n",
        "\n",
        "# Save the transcriptions to a CSV file\n",
        "df = pd.DataFrame(all_transcriptions)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Transcriptions saved to {output_csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LEh4izLhF_fH",
        "outputId": "5fb1bc11-b328-4d61-9271-480bba644fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription for SandalWoodNewsStories_1_part1.wav: ವಣ ಬೇಸಾಯದಲ್ಲಿ ಶ್ರೀಗಂಧ ಕೃಷಿ ಅತಿ ಕಡಿಮೆ ನೀರು ಇರತಕ್ಕಂಥವರು ಬೆಳೆಯಬಹುದು ಅಂದರೆ ನಿಮ್ಮ ಕಣ್ಣು ಕ್ಯಾಮೆರಾ ಕನೆಕ್ಟ್ ಆಯ್ತಪ್ಪ ಅಂದ್ರೆ ನಿಮ್ಮ ಆಧಾರ್ ನಂಬರ್ ತಂತ್ರಜ್ಞಾನ ಸಾಕಷ್ಟು ಡೆವಲಪ್ ಆಗುತ್ತೆ ಒಂದು ಕಿಲೋಮೀಟರ್ ಇವತ್ತು ಕರ್ನಾಟಕ ಸರ್ಕಾರ ಕರ್ನಾಟಕದಲ್ಲಿ ಮಾಡ್ತಾ ಇದೆ ಎರಡು ದಿ ರೇಟ್ ಆಫ್ 5 ಲ್ಯಾಕ್ ರುಪೀಸ್ ಫಾರ್ ಕೆಜಿಎಫ್ ನಮಗೆ ಗೊತ್ತಿರಬೇಕು ಸ್ಯಾಂಡಲ್ವುಡ್ ಕಮರ್ಷಿಯಲ್ ನೇಮ್ ಸ್ಯಾಂಡಲ್ವುಡ್ ಅಂತೀವಿ ಆಸ್ಟ್ರೇಲಿಯಾದವರು ಸ್ಯಾಂಡಲ್ವುಡ್ ಅನ್ನುತ್ತಾರೆ ಸ್ಯಾಂಡಲ್ವುಡ್ ಬಟ್ ನಮ್ಮ ಸ್ಯಾಂಡಲ್ ವುಡ್ ಏನಿದೆಯಲ್ಲ ಅದು ಸ್ಯಾಂಡಲ್ ಆಲ್ಬಮ್ ಅಂತ ಆಸ್ಟ್ರೇಲಿಯಾದ ಸ್ಯಾಂಡಲ್ವುಡ್ ಇದೆ ಅದು ಸ್ಯಾಂಪಲ್ಸ್ ಕ್ರಿಕೆಟ್ ಬೇರೆ ಬೇರೆ ಭಾಗದಲ್ಲಿ ಸುಮಾರು ಹದಿನಾರು ಪ್ರಜಾತಿಯ ಶ್ರೀಗಂಧ ಇದೆ\n",
            "Transcription for SandalWoodNewsStories_1_part2.wav: ವಿಚ್ ಇಸ್ ದ ಐಡಿಯಲ್ ಕೆಮಿಕಲ್ ಕಾಂಬಿನೇಷನ್ ಆಫ್ ಸ್ಯಾಂಡಲ್ವುಡ್ ಅಂದ್ರೆ ಜಗತ್ತಿನಲ್ಲಿ ಉತ್ಕೃಷ್ಟ ಮಟ್ಟದ ಶ್ರೀಗಂಧ ಎಲ್ಲಿಯಾದರೂ ಸಿಗುತ್ತೆ ಅಂದ್ರೆ ಅದು ನಮ್ಮ ಕರ್ನಾಟಕದಲ್ಲಿ ಸಿಗುತ್ತೆ ಅಂದರೆ ಇಲ್ಲಿ ಇರತಕ್ಕಂತ ಭೌತಿಕ ಅಂಶಗಳ ಫ್ಯಾಕ್ಟರ್ಸ್ ಲೈಕ್ ವಾಟರ್ ಅಂಡ್ ಕ್ಲೈಮೇಟ್ ಭೌತಿಕ ಅಂಶಗಳನ್ನು ಮಣ್ಣು ನೀರು ಮತ್ತು ಅವುಗಳ ಜಗತ್ತಿನಲ್ಲೇ ಉತ್ಕೃಷ್ಟ ಮತ್ತು ಶ್ರೀಗಂಧ ಬೆಳೆಯಲಿಕ್ಕೆ ಅದ್ಭುತವಾದ ಪೂರಕ ವಾತಾವರಣ ಈ ನಮ್ಮ ಕನ್ನಡ ನಾಡಿನಲ್ಲಿದೆ ಹಿಂಗಾಗಿ ನಮ್ಮ ಕನ್ನಡ ನಾಡಿಗೆ ಕನ್ನಡ ನಾಡು ಗಂಧದ ನಾಡು ಚಂದನದ ಬೀಡು ಅಂತ ನಿನ್ನೆ ಮನೆ ಕರ್ದಿಲ್ಲ ಶತ್ರು ಶತಮಾನದಿಂದ ಆದಿಕವಿ ರನ್ನ ಪಂಪ ಹಳೆಗನ್ನಡ\n",
            "Transcription for SandalWoodNewsStories_1_part3.wav: ಕನ್ನಡ ನಾಡು ಗಂಧದ ನಾಡು ಚಂದನದ ಬೀಡು ಸಾವಿರ ವರ್ಷದ ಹಿಂದೆ ಸಾವಿರಾರು ವರ್ಷದಿಂದ ಅಂದ್ರೆ ಅವರ ಜ್ಞಾನ ಅದ್ಭುತ ಅಂತ ನಾವು ಅಕ್ಷರ ಕಲಿತಿದ್ದೇವೆ ತಂತ್ರಜ್ಞಾನ ಬೆಳೆದಿದೆ ಸಂಪರ್ಕ ಸಾಧನಗಳಿರಲಿಲ್ಲ ಇವಾಗ ಎಷ್ಟು ಯಾವುದೇ ತಂತ್ರಜ್ಞಾನ ಇರಲಿಲ್ಲ ಆದರೆ ಜಗತ್ತಿನಲ್ಲಿ ಎಲ್ಲಾದರೂ ಅದ್ಭುತವಾದ ಗುಣಮಟ್ಟದ ಶ್ರೀಗಂಧ ಎಲ್ಲಿಯಾದರೂ ಸಿಗುತ್ತದೆ ಅಂದರೆ ಅದು ಕನ್ನಡ ನಾಡಿನಲ್ಲಿ ಸಿಗುತ್ತಾ ಅಂತ ಕಂತ ಜ್ಞಾನ ಅವರಿಗೆ ನೋಡಿ ನಮ್ಮಲ್ಲಿ ಬೇವು ಹಲೋ ಸೂರು ಬನ್ನಿ ಆಲ ಅರಳಿ ಅದ್ಬುತವಾಗಿದೆ ಪರಿಸರ ಕಸರ ಕೊಡುತ್ತದೆ ಅಂತರ್ಜಲ ವೃತ್ತಿ ಮಾಡಲು ದೊಡ್ಡ ಕೊಡುಗೆ ಇದೆ ಆದರೆ ಇದೊಂದು ಕುರುಚಲು ಸಸ್ಯ\n",
            "Transcription for SandalWoodNewsStories_1_part4.wav: ಇದೊಂದು ಪರಾವಲಂಬಿ ಸಸ್ಯ ಇದೆ ಇದು ರಕ್ತಚಂದನ ಸ್ಯಾಂಡಲ್ವುಡ್ ಇವೆಲ್ಲ ಇದೆಲ್ಲ ಪರಾವಲಂಬಿ ಸಸ್ಯ ಡೌನ್ಲೋಡ್ ಬೇಸಿಕಲಿ ಸೆಮಿ ರೂಟ್ ಪ್ಯಾರಾಸೈಟ್ ಅಂತ ಹೇಳ್ತೀವಿ ಇಟ್ ಇಸ್ ಬೇಸಿಕಲಿ ಪ್ಯಾರಾಸಿಟಮಾಲ್ ಸಸ್ಯ ಇಟ್ ಇಸ್ ಬೇಸಿಕಲಿ ಸೆಮಿಸ್ಟರ್ ಸಸ್ಯ ಆದರೆ ಅಂತ ದೊಡ್ಡ ಮರಗಳು ಇದ್ದರೂ ಕೊಡಲು ಆದರೆ ಕನ್ನಡ ನಾಡು ಗಂಧದ ನಾಡು ಚಂದನದ ಬೀಡು ಅಂತೂ ಬಿಕಾಸ್ ಇಲ್ಲಿ ಇರತಕ್ಕಂತ ಜಗತ್ತಿನಲ್ಲೇ ಸಿಗದೇ ಇರತಕ್ಕಂತ ಅದ್ಭುತವಾದ ಭೌತಿಕ ಮಣ್ಣು ನೀರು ಮತ್ತು ಅವುಗಳ ಇಲ್ಲಿ\n",
            "Transcription for SandalWoodNewsStories_1_part5.wav: ಇಲ್ಲಿ ಬರತಕ್ಕಂತಹ ಉತ್ಕೃಷ್ಟ ಮಟ್ಟದ ಶ್ರೀಗಂಧ ಎಲ್ಲಿಯೂ ಬರೋದಿಲ್ಲ ನಾವು ಇತ್ತೀಚಿಗೆ ನಾನು ನೂರಾರು ಎಕರೆ ಶ್ರೀಗಂಧ ಬರ್ತೀನಿ ಮತ್ತು ಈಗ ನಮ್ಮ ಭಾಗದಲ್ಲಿ ಒಂದು 5,000 ಎಕರೆ ಇದೆ 5,000 ಬಿಗ್ಗೆಸ್ಟ್ ಸ್ಯಾಂಡಲ್ವುಡ್ ಕ್ಲಸ್ಟರ್ ಕೊಪ್ಪಳ ಡಿಸ್ಟ್ರಿಕ್ಟ್ ಅಂದ್ರೆ ಇಂಡಿಯಾ ಬಿಗ್ಗೆಸ್ಟ್ ಸ್ಯಾಂಡಲ್ವುಡ್ ಕ್ಲಸ್ಟರ್ ಇದು ಸುಮಾರು ಮೂರು ಜನ ಪ್ರೊಫೆಸರ್ ಕರ್ನಾಟಕದವರು ಆಂಧ್ರದವರು ತಮಿಳುನಾಡು ಇಲ್ಲಿ ನನ್ನ ಫಾರ್ಮ್ ಪಿಎಚ್ಡಿ ಮಾಡಾಕತ್ತಿರಿ\n",
            "Transcription for SandalWoodNewsStories_1_part6.wav: ಕಾಡು ನಿರ್ಮಾಣ ಆಗ್ತಾ ಇದೆ ನಮ್ಮ ಭಾಗದ ಕೊಪ್ಪಳ ಜಿಲ್ಲೆ ಅಂದ್ರೆ ಸಾಧಾರಣ ಅಂತ ತಿಳ್ಕೊಂಡಿದ್ದೀರಾ ಪ್ರಸಾರ ಆಗುತ್ತೆ ಇಲ್ಲೇ ಮೌಲ್ಯವರ್ಧನೆ ಆಗುತ್ತೆ ಇವತ್ತು ಗುಣಮಟ್ಟದ ಶ್ರೀಗಂಧದಿಂದ ಸಾಬೂನುಗಳು ಕಾಸ್ಮೆಟಿಕ್ಸ್ ಪರ್ಫ್ಯೂಮ್ಸ್ ಎಲ್ಲಾ ಎಲ್ಲಾ ಉತ್ಪನ್ನಗಳು ಇಲ್ಲಿ ಉತ್ಪಾದನೆಯಾಗುತ್ತದೆ ಇಡೀ ಜಗತ್ತಿಗೆ ಮಾರುಕಟ್ಟೆ ಕೊಪ್ಪಳ ಕೊಪ್ಪಳ ಆಗುತ್ತದೆ ಅಷ್ಟು ಶಕ್ತಿ ಇದೆ ನಾವು ಜಗತ್ತಿಗೆ ದಾಳಿಂಬೆಯನ್ನು ರಫ್ತು ಮಾಡಿ ಇಡೀ ಜಗತ್ತಿಗೆ ಮಾಡಿದಂತ ಮಣ್ಣಿದು ಇದು ಎಲ್ಲಾ ನೋಡಿದಾಗ ಇದು ದೊಡ್ಡ ದೊಡ್ಡ ಯಶೋಗಾಥೆಗಳು ಹಿಂಗಾಗಿ ಇವತ್ತು ಇಡೀ ಜಗತ್ತಿಗೆ ಇವತ್ತು 5000 ಎಕರೆ ಇವತ್ತು ನಮ್ಮ ಕೊಪ್ಪಳ ಜಿಲ್ಲೆಯಲ್ಲಿ ಆಗ್ತಾ ಇದೆ 15,000 ಕೋಟಿ ಕಚ್ಚಾ ಪದಾರ್ಥ ಮುಂದಿನ ದಿನದಲ್ಲಿ ಕೊಡಬಲ್ಲವನು ಆ ಶಕ್ತಿ ನಮ್ಮ ಈ ನೆಲಕ್ಕೆ 15,000 ಕೋಟಿ ಪ್ರಾಡಕ್ಟ್\n",
            "Transcription for SandalWoodNewsStories_1_part7.wav: ಆಮೇಲೆ ಕೋಟಿ ಕೋಟಿ ಅದರಲ್ಲಿ ಆರ್ಥಿಕ ಬದುಕಿದೆ ಆರ್ಥಿಕ ಬದುಕಿದೆ ಆರ್ಥಿಕ ಬದುಕು ನಮ್ಮ ಒಂದು ಸ್ವಾಭಿಮಾನದ ಬದುಕು ಒಂದು ಸದೃಢ ಬದುಕು ಒಂದು ಗುಣಮಟ್ಟದ ಬದುಕಿಗೆ ಬೇಕು ಆ ವಾಸ್ತವ ಪ್ರಜ್ಞೆ ನಮಗೆ ಇರಬೇಕು ಆದರೆ ಇವತ್ತು ಏನು ಶ್ರೀಗಂಧ ಆಧಾರಿತ ಕೃಷಿ ಅರಣ್ಯ ಅಂತ ನಾವೇನ್ ಮಾಡ್ತೀವಿ ಸ್ಯಾಂಡಲ್ ವುಡ್ ಸೆಂಟ್ರಲ್ ಫಾರೆಸ್ಟ್ರಿ ಮಾಡೆಲ್ ಅಂತ ಇದೆ ಇದರಲ್ಲಿ ಕೇವಲ ಆರ್ಥಿಕ ಅಷ್ಟೇ ಇಲ್ಲ ಆರ್ಥಿಕ ಬದುಕಿನ ಜೊತೆಗೆ ಆರೋಗ್ಯದ ಬದುಕಿದೆ ಒಂದು ಆದರ್ಶದ ಬದುಕಿದೆ ಒಂದು ಆಧ್ಯಾತ್ಮದ ಬದುಕು ಇದೆ ಇಲ್ಲಿ ಏನಂತ ಅಂದ್ರೆ ಅವರ ರೈತ ತಾನು ಬೆಳೆಯುವುದರ ಜೊತೆಗೆ ಪ್ರಾಣಿ ಪಕ್ಷಿಗೆ ಆಶ್ರಯ ಕೊಟ್ಟು ಪರಿಸರಕ್ಕೆ ಕೊಟ್ಟು ಒಂದು ಸೋಶಿಯಲ್ ರೆಸ್ಪಾನ್ಸಿಬಿಲಿಟಿ ಸಾಮಾಜಿಕ ಜವಾಬ್ದಾರಿ ನಿರ್ವಹಣೆ ಮಾಡಿ ಆರ್ಥಿಕವಾಗಿ ಸದೃಢ ಆಗುತ್ತ ಇವತ್ತು ತಾಪಗಳು ಇರುತ್ತವೆ\n",
            "Transcription for SandalWoodNewsStories_1_part8.wav: ಯಾಕ್ ನಮ್ಮ ಹಿರಿಯರು ಕೋಟಿ ವಿದ್ಯೆಗಿಂತ ಮೇಟಿ ವಿದ್ಯೆ ಮೇಲು ಅಂತರ ಯಾಕೆ ಅಂತ ಅಂದ್ರೆ ಬೇರೆ ನೀವು ಅದೇ ಕಾಲಘಟ್ಟದಲ್ಲಿ ಯಾವಾಗ ನಮ್ಮ ಹಿರಿಯರು ನೆನ್ನೆ ಮೊನ್ನೆ ಹೇಳಿದ್ದಲ್ಲ ಇದು ಕಂಪ್ಯೂಟರ್ ಬಂದಿಲ್ಲ ಬಂದಿಲ್ಲ ಇವತ್ತು ಶತಶತಮಾನದಿಂದ ನಮ್ಮ ಅಜ್ಜ ಮತ್ತು ಕೃಷಿತೋ ನಾಸ್ತಿ ದುರ್ಭಿಕ್ಷಂ ಅಂತ ಹೇಳಿದರು ಆದರೆ ಕೃಷಿ ವಿಷಯಕ್ಕೆ ಬಂದಾಗ ಎಷ್ಟು ಗೌರವಕ್ಕೆ ಯಾಕೆಂದರೆ ಒಂದು ಸೋಶಿಯಲ್ ರೆಸ್ಪಾನ್ಸಿಬಿಲಿಟಿ ಸಾಮಾಜಿಕ ಜವಾಬ್ದಾರಿ ನಿರ್ವಹಣೆ ಮಾಡುತ್ತದೆ\n",
            "Transcription for SandalWoodNewsStories_1_part9.wav: ಕೆ ಶಾಸಕರು ಸಿದ್ದ ತೊಂದರೆ ಎದುರಿಸುವಂತ ಶಕ್ತಿ ನಮ್ಮ ದೈಹಿಕ ಶಕ್ತಿ ಒತ್ತಡದ ಬದುಕು ಇದರಿಂದ ಅದನ್ನು ಸ್ಟಡಿ ಮಾಡ್ದಾಗ ಗೊತ್ತಾಗುತ್ತೆ ಬಟ್ ಅದನ್ನ ಎದುರಿಸುವಂತ ದೈಹಿಕ ಶಕ್ತಿ ನಮಗಿಲ್ಲ ಬಾಳ ಏನಾಗಿ ಬಿಟ್ಟಿವಿ ಸಣ್ಣದೊಂದು ನೆಗಡಿ ಬಂದರು ಕೊಡಲು ನಮಗೆ ಟ್ಯಾಬ್ಲೆಟ್ಸ್ ಬೇಕು ಅದಕ್ಕೆ ಇಂಜೆಕ್ಷನ್ ಬೇಕು ಒಂದು 5000 ಖರ್ಚಾಗುತ್ತೆ ಬಂದಾಗ ಇವತ್ತ್ ಏನಾಯ್ತು ಕೋರೋಣ ಅಂತ ಇನ್ನೂ ಬರ್ತಾಳೆ\n",
            "Transcription for SandalWoodNewsStories_1_part10.wav: ಇನ್ನು ಏನಾಗ್ತಾ ಇದೆ ಅಂತ ಅಂದ್ರೆ ಈಗ ನೀವು ನೋಡಿ ಜೀರೋ ಡಸ್ಟ್ ಇಲ್ಲಿ ಎಸ್ ಅದು ನಮ್ಮ ಸಹೋದರರ ಜೊತೆ ಮಾತಾಡ್ತಾ ಇದ್ವಿ ಇಷ್ಟು ಹೊತ್ತು ಮುಂಚೆ ಈಗ ನಿಮಗೆ ಬೆಂಗಳೂರು ಭಾಗದಲ್ಲಿ ಏನಂತೀರಿ ಕೊಪ್ಪಳ ಜಿಲ್ಲೆ ಅಲ್ಲಿ ಬಿಸಲು ಬರಗಾಲ ದೂಳ ಹೋಗೆ ಅಲ್ಲಿ ಬಡತನ ಬಡತನ ಅಲ್ಲಿ ಒಂದು ನೆರಳಿಲ್ಲ ನೀರು ಇಲ್ಲ ಇಲ್ಲ ಅದು ತಪ್ಪು ಈಗ ಜಗತ್ತಿಗೆ ಇವತ್ತು ಗಂಧ ಕೊಡತಕ್ಕದ್ದು ಇಲ್ಲೊಂದು ಮಲೆನಾಡಿನ ಸೃಷ್ಟಿ ಮತ್ತು ಮಾಡ್ತಾ ಇದ್ದೀವಿ ನಮ್ಮ ಎಲ್ಲಾ ನಾವು ಈಗ ಏನು ಅಂತೀವಿ ನಮ್ಮದೊಂದು ಸಂಪೂರ್ಣ ಒಂದು ಗುಂಪು ಇದೆ ಬಿಸಿಲು ನಾಡಿನಲ್ಲಿ ಒಂದು ಕಾಡು ಕಟ್ಬೇಕು ಆ ಕಾಡು ಗಂಧದ ಕಾರ್ಡ್ ಆಗಿರಬೇಕು ಆಮೇಲೆ ಇಟ್ ಇಸ್ ವೆರಿ ನೆಟ್ ಇಸ್\n",
            "Transcription for SandalWoodNewsStories_1_part11.wav: ಇದಕ್ಕೆ ಯಾವುದೇ ಒಂದು ದೊಡ್ಡ ಬಂಡವಾಳ ಬೇಕಾಗಿಲ್ಲ ಈಗ ನಮ್ಮಲ್ಲಿ ಕೇಳುತ್ತಾ ಇರುತ್ತಾರೆ ಒಂದಿಷ್ಟು ಅಂದ್ರೆ ಈಗ ನಿಮ್ಮಲ್ಲಿ ಒಂದು ಕಮೆಂಟ್ ಬರಬಹುದು ನಿಮ್ಮ ಯೂಟ್ಯೂಬಲ್ಲಿ ಇದನ್ನು ಪ್ರಸಾರ ಮಾಡಿದಾಗ ಇಲ್ಲ ಇದು ಒಂದು ಇಂಗೆ ಇದನ್ನು ಮಾಡುತ್ತಿದ್ದಾರೆ ಅಂತ ಒಂದಿಷ್ಟು ಮಂದಿ ಇರ್ತಾರೆ ಯಾವಾಗಲು ಒಂದು ಬಲವಾದ ನಂಬಿಕೆ ಆತ್ಮವಿಶ್ವಾಸ ಕೆಲಸದ ಮೇಲೆ ಶ್ರದ್ಧೆ ಅದು ಬೇಕು ನಾನು ಒಂದು ಕೆಲಸ ಬೇಕು ಒಂದು ಇವತ್ತು ಏನಾಗ್ತಾ ಇದೆ\n",
            "Transcription for SandalWoodNewsStories_1_part12.wav: ನಾವೆಲ್ಲಾ ನೋಡ್ತಾ ಇರ್ತೀವಿ ದೊಡ್ಡ ಶ್ರೀಮಂತನ ಮಗ ಯಾವುದ್ಯಾವುದೋ ರಾಜ್ಯದಲ್ಲಿ ಓದುತ್ತಿದ್ದರು ಬಲವಾದ ನಂಬಿಕೆ ಆತ್ಮವಿಶ್ವಾಸ ಕೆಲಸದ ಮೇಲೆ ಶ್ರದ್ದೆ ಆ ಕನ್ಸಿಸ್ತೆಂಟ್ ಎಫರ್ಟ್ ಬೇಕಲ್ಲ ಹಿಂಗಾಗಿ ಇವತ್ತು ಏನಾಗಿದೆ ಅಂತ ಅಂದ್ರೆ ಶ್ರೀಗಂಧ ನಾವು ಎರಡನೇ ಜನರೇಷನ್ ರೈತರು ನಮ್ಮ ತಂದೆ ಆರ್ಥಿಕವಾಗಿ ಒಂದು ಸದೃಢವಾಗಿ ನಮ್ಮ ತಂದೆ ದೇವೇಂದ್ರಪ್ಪ ಈ ಭಾಗದಲ್ಲಿ ಚಿರಪರಿಚಿತವಾದ ಹೆಸರು ಈಗಾದರೂ ರಾಷ್ಟ್ರೀಯ ದಾಳಿಂಬೆ ಬೆಳೆಗಾರರ ಸಂಘದ ಉಪಾಧ್ಯಕ್ಷರು ನ್ಯಾಷನಲ್ ಪೋನ್ ಗ್ರೇಟ್ ಅಸೋಸಿಯೇಷನ್ ನಮ್ಮ ತಂದೆ ಒಂದು ಭದ್ರವಾದ ಒಂದು ಆರ್ಥಿಕ ಬುನಾದಿ ಹಾಕಿದ್ದಾರೆ ಅತಿ ಕಡಿಮೆ ನೀರು\n",
            "Transcription for SandalWoodNewsStories_1_part13.wav: ಅವನಲ್ಲಿ ಬೋರ್ವೆಲ್ ಇಲ್ದೇನೆ ಗಿಡ ಬೆಳೆಯಬಹುದು ಸ್ವಲ್ಪ ಒಂದು ಎರಡು ಬ್ಯಾಸಿಗೆ ಶ್ರಮಪಡಬೇಕು ಅವನ್ನು ನಾನು ಮತ್ತೆ ಹಂಗೆ ಮಾತಾಡ್ತಿಲ್ಲ ಮಾಡಿದಿವಿ ವಣ ಬೇಸಾಯದಲ್ಲಿ ಶ್ರೀಗಂಧ ಮಾಡತಕ್ಕದ್ದು ಮನೆ ಬೇಸಾಯದಲ್ಲಿ ಶ್ರೀಗಂಧ ಕೃಷಿ ಅದನ್ನು ಒಂದು ತೋಟದಲ್ಲಿ ಒಂದು ಇದನ್ನೇ ಮಾಡ್ತಾ ಇದ್ದೀವಿ ಈಗ ಟೋಟಲ್ ಬೇಸಾಯದಲ್ಲಿ ಶ್ರೀಗಂಧ ಕೃಷಿ ಮಾಡಬಹುದು ಅದು ಹೇಗೆ ಸಾಧ್ಯ ಇಲ್ಲ ಅನ್ನುತ್ತಾ ಇದೆ ಮಾಡಿದ್ದು ಅಲ್ಲಿ ಯಾವುದೇ ನೀರಿನ ಮೂಲಗಳು ಇಲ್ಲ ಬರುವುದಿಲ್ಲ ಶ್ರೀಗಂಧ ನಾನು ಹೇಳ್ತಾ ಇದೀನಿ ಆಮೇಲೆ ತಾವು ಕೇಳ್ತಾ ಇದ್ದೀರಿ ಬಟ್ ಇದಕ್ಕೆ\n",
            "Transcription for SandalWoodNewsStories_1_part14.wav: ಗಂಧದ ನಾಡು ಇದು ಆದರೆ ಇದು ಜೊತೆಗೆ ಇದಕ್ಕೆ ಜಾಗತಿಕ ಮಾರುಕಟ್ಟೆಯಲ್ಲಿ ಇವತ್ತು ದೊಡ್ಡ ಬೆಲೆ ಇದೆ ದೊಡ್ಡ ಬೆಲೆ ಇದೆ ತಮಗೆ ಭವಿಷ್ಯ ಗೊತ್ತಿರುತ್ತದೆ ಸ್ಯಾಂಡಲ್ವುಡ್ ಆಯಿಲ್ ಒಂದು ಗುಣಮಟ್ಟದ ಶ್ರೀಗಂಧದ ಎಣ್ಣೆ ಇವತ್ತು ಕೆ ಎಸ್ ಡಿ ಎಲ್ ಅಂತ ಮೈಸೂರ್ ಸ್ಯಾಂಡಲ್ ಸರ್ಕಾರಿ ಡೀಟೇಲ್ಸ್ ಕೆ ಎಸ್ ಡಿ ಎಲ್ ರಿಟರ್ನಿಂಗ್ ಮಾಡ್ತಾ ಇದೆ 5 ಗ್ 10 ಗ್ರಾಂ ಎರಡು ಪ್ಯಾಕಿಂಗ್ ಒಂದು ತುಲ್ಲಿಗೆ ಎರಡುವರೆ ಸಾವಿರ ಬೇಕು ಮಾತಾಡಬೇಕು ಇವತ್ತು ನೋಡಿ ಒಂದು ಚಳಿ ಶ್ರೀಗಂಧದಲ್ಲಿ 5000 ಅಂದ್ರೆ 10ಗ್ರಾಂ 10 ಗ್ 5000 ಆದರೆ 100 ಗ್ರಾಂ 50,000 ಗ್ರಾಂ 5 ಲಕ್ಷ ಒಂದು ಕಿಲೋಮೀಟರು ಕರ್ನಾಟಕ ಸರ್ಕಾರ\n",
            "Transcription for SandalWoodNewsStories_1_part15.wav: ಕರ್ನಾಟಕದಲ್ಲಿ ಮಾಡ್ತಾ ಇದೆ ಎರಡು ರೇಟ್ ಆಫ್ 5 ಲ್ಯಾಕ್ ರುಪೀಸ್ ಪರ್ ಕೆಜಿ ನಮಗೆ ಗೊತ್ತಿರಬೇಕು ಇವತ್ತು ಕರ್ನಾಟಕ ಸರ್ಕಾರ ಕರ್ನಾಟಕದಲ್ಲಿ ಇವತ್ತು ಮಾಡ್ತಾ ಇದೆ ಒಂದು ಕಿಲೋ ಶ್ರೀಗಂಧದ ಎಣ್ಣೆ 5 ಲಖ್ ಅದು ನಮ್ಮ ಡೈಲಾಗ್ ಕಂಟೆಂಟ್ ಗೆ ಬೀಳುತ್ತದೆ ಅಂದ್ರೆ ಇವತ್ತು ಏನಿದು ಬೆಳಿತದ ಸಹಜವಾಗಿ ಬೆಳೆಯುತ್ತದೆ ಗುಣಮಟ್ಟದ ಶ್ರೀಗಂಧ ಬರುತ್ತದೆ ಯಾವುದೇ ಅದಕ್ಕೆ ಕೀಟಬಾಧೆ ಇಲ್ಲ ರೋಗ ಬಾಧೆ ಇಲ್ಲ ಅಂದ್ರೆ ನಾವು ಆ ಪದ್ಧತಿ ಪ್ರಕಾರ ಆ ಪ್ರಕಾರ ಇದಕ್ಕೆ ಯಾವುದೇ ಸೂರಿಗಳು ವೆಚ್ಚ ಇಲ್ಲ ಆದರೆ ಇದರ ಬೆಲೆ ಇರುವುದರಿಂದ ಸ್ಟ್ರೆಂತ್ ವೀಕ್ನೆಸ್ ಆಪರ್ಚುನಿಟಿ ಅಂಡ್ ಥರ್ಡ್ ಸಂಧಿ\n",
            "Transcription for SandalWoodNewsStories_1_part16.wav: ಶಾಕ್ ಚಾಲೆಂಜ್ ಚಾಲೆಂಜ್ ಸ್ಯಾಂಡಲ್ವುಡ್ ಮೇಲೆ ಚಾಲೆಂಜ್ ಅಂದಿದೆ ರಕ್ಷಣೆ ಪ್ರೊಟೆಕ್ಷನ್ ಬಿಕಾಸ್ ಇಟ್ ಹ್ಯಾಸ್ ದೊಡ್ಡ ಬೆಲೆ ಬೆಲೆ ದೊಡ್ಡ ಬೆಲೆ ಬೆಲೆ ಏನ್ ಮಾಡ್ತಾರೆ ಅಂದ್ರೆ ಗವರ್ನಮೆಂಟ್ ಜಾಗದಲ್ಲಿ ಅದು ಎಲ್ಲರ್ದು ಸಾರ್ವಜನಿಕ ಅದು ಎಲ್ಲರ್ದು ಆಸ್ತಿ ಬಟ್ ಯಾರ್ದು ಅಲ್ಲ ಸರ್ಕಾರ ಆಫೀಸ್ ಎಲ್ಲಾರ್ದು ಆಫೀಸ್ ಗೋರ್ಮೆಂಟ್ ಹಾಸ್ಪಿಟಲ್ ಅದು ಸಾರ್ವಜನಿಕ ಏ ಯಾಕೆ ನಾನು ನಾನು ಇದು ಎಲ್ಲರಿಗೂ ತಿನ್ನುತ್ತಾನೆ\n",
            "Transcription for SandalWoodNewsStories_1_part17.wav: ಅವ್ನ್ ಮನೆ ಅಲ್ನೋಡಿ ಹಾಸ್ಪಿಟಲ್ ಎಷ್ಟು ಕಟ್ಟಡ ಎಷ್ಟು ಚೆನ್ನಾಗಿರುತ್ತದೆ ಎಲ್ಲಾ ಹೊಲಸು ಮಾಡಿರುತ್ತಾರೆ ಹೌದು ಹೌದು ಅದಕ್ಕೆ ಯಾರು ಜವಾಬ್ದಾರಿ ಇಲ್ಲ ಅದು ಸಾರ್ವಜನಿಕ ಕೂಸು ಪಬ್ಲಿಕ್ ಪಬ್ಲಿಕ್ ಪ್ರಾಪರ್ಟಿ ಪಟ್ಟಿಲ್ಲ ಈಗ ನಿಮ್ಮದು ಎಲ್ಲಾ ನನ್ನ ಆಧಾರ್ ನಂಬರ್ ಹೇಳ್ತೀನಿ ಈಗ ನೀವು ಒಂದು ಮೂರು ಕ್ಯಾಮೆರಾದಲ್ಲಿ ಕವರ್ ಆದರೆ ನಮ್ಮಲ್ಲಿ ಏನು ಕ್ಯಾಮೆರಾ ಇದೆ ಅಂದ್ರೆ ನಿಮ್ಮ ಕಣ್ಣು ಕ್ಯಾಮೆರಾ ಕನೆಕ್ಟ್ ಆಯ್ತಪ್ಪ ಅಂದ್ರೆ ನಿಮ್ಮ ಆಧಾರ್ ನಂಬರ್ ಟೆಕ್ನಾಲಜಿ ಇಷ್ಟು ಡೆವಲಪ್ ಆಗಿದೆ ಇವತ್ತು ಜಾಗತಿಕ ಮಾರುಕಟ್ಟೆ ಆಗಿದೆ ಗ್ಲೋಬಲೈಸೇಶನ್\n",
            "Transcription for SandalWoodNewsStories_1_part18.wav: ಇವತ್ತಿನ ತಂತ್ರಜ್ಞಾನ ನಾವು ಮಾಡಿಕೊಳ್ಳಬೇಕು ಅಂದರೆ ಇದರ ಬೆಲೆ ಇರುವುದರಿಂದ\n",
            "Transcription for SandalWoodNewsStories_1_part19.wav: ಪೂರಕವಾದ ಕ್ರಮಗಳನ್ನು ತಗೋಬೇಕು ಈಗ ನಮಗೆ ಅವಕಾಶಗಳು ಏನಿದೆ ತಂತ್ರಜ್ಞಾನ ಇದೆ ಸಾಕಷ್ಟು ತಂತ್ರಜ್ಞಾನ ಇವತ್ತು ಕ್ಯಾಮೆರಾಗಳನ್ನು ಇಡಬಹುದು ಸೆನ್ಸರ್ಸ್ ಗಳನ್ನು ಇಡಬಹುದು ಡಾಗ್ಸ್ ಗಳನ್ನು ಹಾಕಬೇಕು\n",
            "Transcription for SandalWoodNewsStories_1_part20.wav: ನಿಮಗೆ ನೋಡ್ತೀರಲ್ಲ ಯಾಲಕ್ಕಿ ಲವಂಗ ದಾಲ್ಚಿನ್ನಿ ಎಲ್ಲಾ ಸ್ಮೆಲ್ ಇದು ಬರುವಂತದು ಹಾಲ್ ಸ್ಪೈಸ್ ಅಂತ ಎಗ್ ಫ್ರೂಟ್ ಅಂತ ಎಗ್ ಫ್ರೂಟ್ ಅಂತ ಬರುತ್ತದೆ ಅಂದ್ರೆ ಪ್ರಕೃತಿಯೊಳಗೆ ಭಗವಂತ ಎಲ್ಲಾ ಕೊಟ್ಟಿದ್ದಾನೆ ಅಂತ\n",
            "Transcription for SandalWoodNewsStories_1_part21.wav: ಇವೆಲ್ಲ ನಮ್ಮಲ್ಲಿ ಬರೋದಿಲ್ಲ ಸಾಂಬಾರ್ ಪದಾರ್ಥಗಳು ಅಂತ ಅಂದ್ರು ಯಾಕೆ ಬರುವುದಿಲ್ಲ ಆದರೆ ಇಲ್ಲಿ ಒಂದು ಮಲೆನಾಡಿನ ವಾತಾವರಣ ನಿರ್ಮಾಣಕ್ಕೆ ಲವಂಗ ಕರಿ ಮೆಣಸು ಕರಿಮೆಣಸು\n",
            "Transcription for SandalWoodNewsStories_1_part22.wav: ಇದು ಯಾಲಕ್ಕಿ ಯಾಲಕ್ಕಿ ನೋಡಿ ನೀವು ಈಗ ಕೊಪ್ಪಳ ಜಿಲ್ಲೆಯಲ್ಲಿ ಶೂಟ್ ಮಾಡ್ತಾ ಇದೀನಿ ಅಂತ ಕಾಫಿ ಕಾಫಿ ಏನು ಆಗಿಲ್ಲ ನೋಡಿ ಪೇಪರ್\n",
            "Transcription for SandalWoodNewsStories_1_part23.wav: ಹಿಂಗಾಗಿ ಅಂದ್ರೆ ಒಂದು ಪೂರಕ ವಾತಾವರಣ ಮಾಡಬೇಕು ಡಿಸ್ಟ್ರಿಬ್ಯೂಷನ್ ತೋಟಗಾರಿಕೆ ಇಲ್ಲಿಂದ ಮಾಡ್ತೀವಿ ಇಲ್ಲ ಬೊಕ್ಕ ಅಂತ ಫ್ರೂಟ್ ಇದು ನೀವು ನೋಡಿದಿರಲ್ಲ ಅದೇ ಕಾಯಿಗಳು ಬಿಟ್ಟಿದೆ ನೋಡಿ ಸಿಂಧೂರ್ ಜೊತೆ ಮಾತಾಡಿ ಅಂತ ಹೇಳುತ್ತದೆ\n",
            "Transcription for SandalWoodNewsStories_1_part24.wav: ಗೋಲ್ಡನ್ ಬ್ಯಾಂಬು ಅಂತ ಇದೆ\n",
            "Transcription for SandalWoodNewsStories_1_part25.wav: ಆಮೇಲೆ ಬುದ್ಧ ಬ್ಯಾಂಬು ಅಂತ ಇದೆ ರೀತಿ ಬರುತ್ತದೆ ಕಲಾ ಮಾಧ್ಯಮದ ಎಲ್ಲಾ ಎಪಿಸೋಡುಗಳು ನಿಮಗೆ ಸಿಗಬೇಕು ಅಂತ ಅಂದ್ರೆ ಕಲಾ ಮಾಧ್ಯಮ ಯುಟ್ಯೂಬ್ ಚಾನೆಲ್ನ ಸಬ್ಸ್ಕ್ರೈಬ್ ಮಾಡಿ ಬೆಲ್ ಐಕಾನ್ ಅನ್ನು ಕ್ಲಿಕ್ ಮಾಡಿ ತಪ್ಪದೆ ಮಾಡಿ ಸ್ನೇಹಿತರೆ ಎಲ್ಲಾ ಸಂದರ್ಶನಗಳನ್ನು ನೀವೀಗ ಓದಬಹುದು www.com ಈ ವೆಬ್ಸೈಟ್ ಗೆ ವಿಸಿಟ್ ಮಾಡಿ ಇಂಟರ್ವ್ಯೂ ಗಳನ್ನು ಓದಿ ಓದುವ ಸಂಸ್ಕೃತಿ ಹೆಚ್ಚಾಗಲಿ ಧನ್ಯವಾದ\n",
            "Transcription for SandalWoodNewsStories_1_part26.wav: Unable to recognize speech\n",
            "Transcription for SandalWoodNewsStories_146_part1.wav: ಸುಸ್ಥಿರ ಕೃಷಿ ಅಂತ ನೀವು ಏನ್ ಹೇಳ್ತೀರಿ ಶಾರ್ಟ್ ಟೈಮ್ ಮಾಡೋಕೆ ಆಗದೆ ಇದ್ದಾಗ ಬೇರೆಯವರಿಗೆ ಮತ್ತು ಗಿಡ ಮರಗಳು ಇದ್ರೇನೆ ಅವ್ನ್ ಸರ್ವೆ ವಾಗದು ಮಾವು ಇದೆ ಮತ್ತೆ ಸೀಬೆ ಇರುತ್ತೆ ಅಥವಾ ಎಲ್ಲೆಲ್ಲಿ ಜಾಗ ಇರುತ್ತೆ ಅಂತ ಕಡೆ ಒಂದೊಂದು ಗಂಧದ ಗಿಡಗಳನ್ನು ಬೆಳೆಸುವುದಕ್ಕೆ ನಾವು ಈ ತರ ಡೆಮೋ ಸ್ಟೇಷನ್ ಮಾಡ್ತೀವಿ ಗಂಧ ಒಂದು ಪ್ಯಾರಾಸೈಟ್ ಅದು ಅಂದ್ರೆ ಅದಾಗಿ ಅದು ತನ್ನ ನ್ಯೂಟ್ರಿಯೆಂಟ್ಸ್ ನ ಜನರೇಟ್ ಮಾಡ್ಕೊಳಕ್ಕೆ ಆಗಲ್ಲ ಅದಕ್ಕೋಸ್ಕರ ಅದು ಬೇರೆ ಬೇರೆ ಗಿಡಗಳ ಬೇರಿನ ಜೊತೆಗೆ ಸೇರಿಕೊಂಡು ಒಬ್ಸರ್ವ್ ಮಾಡಿಕೊಳ್ಳುತ್ತೆ ಈಗ ನಿಮಗೆ ಏನು ಪಕ್ಕದಲ್ಲಿ ಏನು ಗಿಡ ಇಲ್ಲದೆ ಇರಬಹುದು ಆದರೆ ಇಲ್ಲೆಲ್ಲಾ ಇಷ್ಟೊಂದು ಇದೆಲ್ಲ ಇದೆ ಅಲ್ಲ ಅದು ನಮ್ಮ ಡೆಮೋ ಸ್ಟೇಷನ್ ಪ್ರಕಾರ ಎಲ್ಲಿ ಸೀತಾಫಲ ಗಿಡಗಳು ನಾವು ಹಾಕಿದ್ದೀವಿ ಆಗುತ್ತೆ\n",
            "Transcription for SandalWoodNewsStories_146_part2.wav: Unable to recognize speech\n",
            "Transcription for SandalWoodNewsStories_146_part3.wav: ನಿಂಗೆ ಏನು ಸಿಗೋದಿಲ್ಲ ಅದಕ್ಕೋಸ್ಕರ ಸುಮಾರು ಒಂದು ಎಕರೆಯಲ್ಲಿ ಒಂದು 50 60 ಇರಬೇಕು ಅಂತ ನಮಗೆ ಫಾರೆಸ್ಟ್ ಇದ್ದಾಗ ಏನಾಗುತ್ತೆ ಅದು ವುಡ್ ಸಿಗುತ್ತೆ ಆಮೇಲೆ ನೇಚರ್ ಗೆ ಹೆಲ್ಪ್ ಆಗುತ್ತೆ ನಮಗೆ ರೈತರಿಗೆ ಇದರ ಮಧ್ಯದಲ್ಲಿ ಏನು ಬೇಕಾದರೂ ಗೋಲ್ಡನ್ ಸಿದ್ದಪ್ಪ ಅದು ರೇಟ್ ಸೀತಪ್ಪ ಅಲ್ಲ ಇದು ಗೋಲ್ಡ್ ಸೀತಾಫಲ ಹೀಗೆ ಪೀನಟ್ ಬಟರ್ ಗಳು ಈ ತರ ಇದೆ ಮತ್ತೆ ಈ ಗಿಡಗಳು ಬೆಳೆಯುವುದರಿಂದ ನಮಗೇನು ಅನುಕೂಲ ಆಗುತ್ತೆ ಅಂದ್ರೆ ಇಲ್ಲಿ ನೋಡಿಲ್ಲಿ ಈ ಟೊಮೇಟೊ ಬಿದ್ದೋಗಿದೆ ಕಟ್ಟಬೇಕು ಇದು ನ್ಯಾಚುರಲ್ ಆಗಿರುತ್ತದೆ\n",
            "Transcription for SandalWoodNewsStories_146_part4.wav: ಒಂದು ಎಕರೆಗೆ 10 ಟನ್ ಬೆಳೆಯುವ ಒಂದು ಪರಿಸ್ಥಿತಿ ಇಲ್ಲದೆ ಇರಬಹುದು ಬಟ್ ಒಟ್ಟಾರೆ ನೀವು ತಗೊಂಡಾಗ ನಮಗೆ ಪರಿಸರ ಮತ್ತು ಆಹಾರ ಸುಸ್ಥಿರ ಕೃಷಿ ಅಂತ ನೀವು ಏನು ಹೇಳುತ್ತೀರಿ ಶಾರ್ಟ್ ಟೈಮ್ ಇರಬೇಕು ರೈತ ರಿಟೈರ್ಡ್ ಆಗಿ ಅವನ ಕೈಯಲ್ಲಿ ವ್ಯವಸಾಯ ಮಾಡಕ್ಕೆ ಆಗದೆ ಇದ್ದಾಗ ಬೇರೆಯವರಿಗೆ ಮತ್ತು ಗಿಡ ಮರ\n",
            "Transcription for SandalWoodNewsStories_146_part5.wav: Unable to recognize speech\n",
            "Transcription for SandalWoodNewsStories_148_part1.wav: Unable to recognize speech\n",
            "Transcription for SandalWoodNewsStories_148_part2.wav: ಬೆಳೆಗಳು ಯಾವ ಕೊಟ್ರೆ ಅಷ್ಟೇ\n",
            "Transcription for SandalWoodNewsStories_156_part1.wav: ಸರಿಗ ಮೊದಲನೇ ಪ್ರಶ್ನೆ ಏನು ಅಂತ ಹೇಳಿದ್ರೆ ಶ್ರೀಗಂಧದ ಮರ ಅಂತ ಹೇಳಿದರೆ ಎಲ್ಲೋ ಒಂದು ರೀತಿಯಲ್ಲಿ ಬೇರೆ ಪರೀಕ್ಷೆಗಳಿಗೆ ಹೋಲಿಸಿದಲ್ಲಿ ಇದು ಖಂಡಿತ ಯಾವ ಒಂದು ವಿಧದಲ್ಲಿ ಇದು ಎದೆ ಮರಗಳಿಗಿಂತ ವೈಶಿಷ್ಟ್ಯವಾಗಿದೆ ಪ್ರಶ್ನೆ ಶ್ರೀಗಂಧದ ಮರ ವೈಶಿಷ್ಟ್ಯತೆ ಬಗ್ಗೆ ಹೇಳಬೇಕಾದರೆ ಅದು ಮೊದಲನೇದಾಗಿ ನೋರ್ಮಲ್ ಮರತರ ಅಲ್ಲ ಅದು ಒಂದು ಹೆಮ್ಮೆ ರೂಟ್ ಪ್ಯಾರಾಸೈಟ್ ಮೇಲೆ ಅವಲಂಬಿತವಾಗಿರುತ್ತದೆ ಮರ ಇದರಲ್ಲಿ ಸ್ಪೆಷಲ್ ಆಗಿ ಏನೆಂದರೆ ಶ್ರೀಗಂಧದ ಕಲರ್ ಕಲರ್ ಮತ್ತು 10ನೇ ವರ್ಷ 7 7 ಇಂದ ಮೇಲ್ಪಟ್ಟು ವರ್ಷಗಳಲ್ಲಿ ಆ ಹಾಡು ಡೆವಲಪ್ ಆಗಿ ಅದರಲ್ಲಿ ಶ್ರೀಗಂಧದ ಎಣ್ಣೆ ತಯಾರಿಯಾಗಿ ಡಿಪೋಸಿಟ್ ಆಗ್ತದೆ ಸೋ ಈ ಶ್ರೀಗಂಧದ ಪರಿಮಳಕ್ಕೆ\n",
            "Transcription for SandalWoodNewsStories_156_part2.wav: ಸಾಕಷ್ಟು ಮತ್ತು ಮೆಡಿಸಿನಲ್ ವ್ಯಾಲ್ಯೂ ಇದೆ ಗುಣ ಇದೆ ಗುಣ ಇರುವುದರಿಂದ ಮತ್ತು ಪರಿಮಳ ಇರುವುದರಿಂದ ಸ್ಪೆಷಲ್ ನಮಗೆ ಮೊದಲು ಬೇಕಾಗಿದ್ದು ಗುಣಮಟ್ಟದ ಸಸಿಗಳು ಎಲ್ಲಿ ಈ ಸಸಿಗಳು ದೊರೆಯುತ್ತದೆ ಶ್ರೀಗಂಧ ಸಸಿಗಳು ನಮ್ಮ ನರ್ಸರಿಗಳಲ್ಲಿ ಎಲ್ಲಾ ಕಡೆ ರಾಜ್ಯದಲ್ಲಿ ನರ್ಸರಿ ಇಲಾಖೆಯಲ್ಲಿ ಸಸಿಗಳನ್ನು ಬೆಳೆಸುತ್ತೇವೆ ಈ ವರ್ಷ ಸುಮಾರು 6,000 ಮೇಲ್ಪಟ್ಟು ಸಸಿ ಬೆಳೆಸಿ ನಾವು ನೆಟ್ಟಿದ್ದೇವೆ ಮತ್ತು ಜನರಿಗೆ ಕೊಡಲಾಗಿದೆ ಕೊಡಲಾಗಿದೆ ಈ ವರ್ಷ ಇಷ್ಟೊತ್ತಿಗೆ ಆಲ್ಮೋಸ್ಟ್ ಎಲ್ಲಾ ಸಸಿ ಖಾಲಿಯಾಗಿದೆ\n",
            "Transcription for SandalWoodNewsStories_156_part3.wav: ಈಗ ಸಿಕ್ಕೋದಿಲ್ಲ ಬಟ್ ಬಾರೋ ವರ್ಷಕ್ಕೆ ಈ ವರ್ಷ ನಾವು ಏನು ಎಷ್ಟು ಇದರ ಬಗ್ಗೆ ಪ್ರಧಾನತೆ ಕೊಟ್ಟಿದ್ವಿ ಮತ್ತು ಸಾಕಷ್ಟು ಪ್ರಚಾರವನ್ನು ಕೊಟ್ಟಿದೆ ಡಿಮ್ಯಾಂಡ್ ಬಹಳ ಇದೆ ಬಹಳ ಜನ ಬಹಳಷ್ಟು ಬೇಡಿಕೆ ಇದೆ ಅಂತ ಬೇಡಿಕೆ ಬಹಳ ಹೆಚ್ಚು ಇದೆ ಸೋ ನನ್ನ ಅನಿಸಿಕೆ ಯಾರು ಈ ವರ್ಷ 6 ಲಕ್ಷಕ್ಕೆ ಇನ್ನು ಹೆಚ್ಚಿನ ಸಂಖ್ಯೆಯಲ್ಲಿ ಬಳಸಲಿಕ್ಕೆ ಇಲಾಖೆ ಮೇಲ್ಪಟ್ಟು ನಾವು ಗೆಲ್ತಾ ಇದ್ದೀವಿ ಸರ್ ಈಗ ಒಂದು ಕರೆ ಇದೆ ಪಾವಗಡದಿಂದ ನಾಗರಾಜ್ ಅವರು ಕರೆ ಮಾಡಿದರೆ ನಾಗರಾಜ್ ಅವರೇ ನಮಸ್ಕಾರ ನಮಸ್ಕಾರ ಇದರ ಬಗ್ಗೆ ಎಷ್ಟು ಅಡಿ ಅಂತರದಲ್ಲಿ ನಾಟಿ ಮಾಡಬೇಕು ಅಂತ ಹೇಳಿ ನಾಗರಾಜ್ ಅವರೇ ಸುಮಾರು 10 ಅಡಿ ಅಂತರದಲ್ಲಿ ನಾಟಿ ಮಾಡಬಹುದು ಅದು ಅಂತರ ಬೆಳೆ ಬಂದಾಗ ನೀವು ಅದು\n",
            "Transcription for SandalWoodNewsStories_156_part4.wav: ಕೆಂಪು ಲೋಮಿ ಸಾಯಿಲ್ ಅಂತ ಹೇಳ್ತೀವಿ ಲೋಮಿ ಸಾಯಿಲ್ ವಿಲ್ಡ್ಸ್ ಬೆಸ್ಟ್ ಮರಗೆ ಆದರೆ ಎಲ್ಲಾ ತರಹದ ಭೂಮಿಗಳಲ್ಲಿ ಇನ್ನು ಬಂದಿದೆ ಚೆನ್ನಾಗಿ ಬೆಳಿತಾ ಇದೆ ಗುಲ್ಬರ್ಗ ಕಡೆ ನೋಡಿದ್ದೇನೆ ಈ ಬ್ಲಾಕ್ ಕಾಟನ್ ಸಾಯಿಲ್ ಅಲ್ಲಿ ಕೂಡ ಎಲ್ಲಾ ರೀತಿಯ ಮಣ್ಣುಗಳಲ್ಲಿ ಚಿತ್ರದುರ್ಗದಿಂದ ಕಿರಣ್ ಅವರು ಕರೆ ಮಾಡಿದರೆ ಕಿರಣ್ ಅವ್ರು ನಮಸ್ಕಾರ\n",
            "Transcription for SandalWoodNewsStories_156_part5.wav: ಪ್ರಾರಂಭಿಕ ಹಂತದಲ್ಲಿ ಯಾವೆಲ್ಲಾ ಪೋಷಕಾಂಶಗಳು ಹಾಕಬೇಕಾಗುತ್ತದೆ\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9e1f88af935f>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Transcribe the audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Print each transcription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-9e1f88af935f>\u001b[0m in \u001b[0;36mtranscribe_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;31m# Transcribe using Google API\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mtranscription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecognize_google\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'kn-IN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtranscription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/recognizers/google.py\u001b[0m in \u001b[0;36mrecognize_legacy\u001b[0;34m(recognizer, audio_data, key, language, pfilter, show_all, with_confidence, endpoint)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m     response_text = obtain_transcription(\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecognizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moperation_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/speech_recognition/recognizers/google.py\u001b[0m in \u001b[0;36mobtain_transcription\u001b[0;34m(request, timeout)\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;34m\"recognition connection failed: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         )\n\u001b[0;32m--> 222\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from deep_translator import GoogleTranslator\n",
        "\n",
        "# Initialize the translator\n",
        "translator = GoogleTranslator(source='kn', target='en')\n",
        "\n",
        "# Load your CSV file from Google Drive (assuming the file is already loaded)\n",
        "csv_path = '/content/drive/MyDrive/audiocorpus/trans.csv'  # Change this to the correct path\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "# Translate each Kannada sentence to English\n",
        "df['English_Translation'] = df['Transcription'].apply(lambda x: translator.translate(x))\n",
        "\n",
        "# Save the updated DataFrame locally in Colab's environment\n",
        "local_csv_path = 'translated_transcriptions.csv'  # This saves it in the current Colab environment\n",
        "df.to_csv(local_csv_path, index=False)\n",
        "\n",
        "# Verify if the file is saved locally\n",
        "print(f\"File saved locally at {local_csv_path}\")\n",
        "!ls  # List files in the current directory to check if the file is saved\n",
        "\n",
        "# Move the file to Google Drive\n",
        "!mv translated_transcriptions.csv /content/drive/MyDrive/  # Move it to the root of Google Drive\n",
        "\n",
        "# You can check if it's successfully moved by listing files in Google Drive\n",
        "!ls /content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa-3IoZJfrk8",
        "outputId": "56abec0b-0ea4-4fb0-b8a6-d232cdbf1b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File saved locally at translated_transcriptions.csv\n",
            "drive  sample_data  translated_transcriptions.csv\n",
            " audiocorpus\t    ProcessedAudio   transcriptions.csv   translated_transcriptions.csv\n",
            "'Colab Notebooks'   report.gdoc      Transcriptions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deep-translator\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To4MdyWrgd9m",
        "outputId": "189e1c98-d928-46f0-919b-f9966e8fd676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce"
      ],
      "metadata": {
        "id": "4j_reEA-ZYBk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd61c9cb-a9e2-498e-9efc-43de44ac6045"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting noisereduce\n",
            "  Using cached noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Using cached noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: noisereduce\n",
            "Successfully installed noisereduce-3.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Function to transcribe audio\n",
        "def transcribe_audio(file_path):\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)  # Record audio from the file\n",
        "        try:\n",
        "            # Transcribe using Google API\n",
        "            transcription = recognizer.recognize_google(audio, language='kn-IN')\n",
        "            return transcription\n",
        "        except sr.RequestError as e:\n",
        "            return f\"API request error: {e}\"\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Unable to recognize speech\"\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Set up folders for audio and CSV output\n",
        "audio_folder = '/content/drive/MyDrive/ProcessedAudio'\n",
        "output_csv_path = '/content/drive/MyDrive/audiocorpus/ttranscriptions.csv'\n",
        "\n",
        "# Initialize an empty list to store all transcriptions\n",
        "all_transcriptions = []\n",
        "\n",
        "# Loop through all audio files in the folder\n",
        "audio_files = [f for f in os.listdir(audio_folder) if f.endswith('.wav')]\n",
        "for audio_file in audio_files:\n",
        "    audio_path = os.path.join(audio_folder, audio_file)\n",
        "\n",
        "    # Transcribe the audio\n",
        "    transcription = transcribe_audio(audio_path)\n",
        "\n",
        "    # Print each transcription\n",
        "    print(f\"Transcription for {audio_file}: {transcription}\")\n",
        "\n",
        "    # Append the file name and transcription to the list\n",
        "    all_transcriptions.append({'File Name': audio_file, 'Transcription': transcription})\n",
        "\n",
        "# Save the transcriptions to a CSV file\n",
        "df = pd.DataFrame(all_transcriptions)\n",
        "df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Transcriptions saved to {output_csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "dRSrl6jgZY2h",
        "outputId": "13277e3e-b2ce-4d08-871f-7f92361de528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'speech_recognition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c19b908fa636>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Initialize recognizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "\n",
        "def load_and_preprocess_audio(file_path):\n",
        "    # Load the audio file using librosa\n",
        "    audio, sr = librosa.load(file_path, sr=None)  # sr=None to preserve original sampling rate\n",
        "\n",
        "    # Apply noise reduction (optional but recommended)\n",
        "    audio_denoised = nr.reduce_noise(y=audio, sr=sr)\n",
        "\n",
        "    # Save the denoised audio to a new file (optional)\n",
        "    sf.write('denoised_audio.wav', audio_denoised, sr)\n",
        "\n",
        "    return audio_denoised, sr\n",
        "\n",
        "# Example usage for one audio file\n",
        "audio_path = os.path.join(audio_folder, audio_files[0])\n",
        "audio, sr = load_and_preprocess_audio(audio_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 671
        },
        "id": "nfgleSb1XuAD",
        "outputId": "545478dd-cde9-40a4-deee-4fc7b3c6815c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-b8a195f8e671>:7: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  audio, sr = librosa.load(file_path, sr=None)  # sr=None to preserve original sampling rate\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172.wav'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172.wav': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-b8a195f8e671>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Example usage for one audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0maudio_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_preprocess_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-b8a195f8e671>\u001b[0m in \u001b[0;36mload_and_preprocess_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_preprocess_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Load the audio file using librosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sr=None to preserve original sampling rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Apply noise reduction (optional but recommended)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-157>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/ProcessedAudio/SandalWoodNewsStories_172.wav'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Initialize recognizer\n",
        "recognizer = sr.Recognizer()\n",
        "\n",
        "# Function to transcribe audio using Google Speech API\n",
        "def transcribe_audio(file_path):\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio = recognizer.record(source)  # Record audio from the file\n",
        "        try:\n",
        "            # Transcribe using Google's API for Kannada language (kn-IN)\n",
        "            transcription = recognizer.recognize_google(audio, language='kn-IN')\n",
        "            return transcription  # Return the transcribed text\n",
        "        except sr.RequestError as e:\n",
        "            return f\"API request error: {e}\"\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Unable to recognize speech\"\n",
        "        except Exception as e:\n",
        "            return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "# Function to transcribe all audio files and save to CSV\n",
        "def transcribe_all_audio_files(audio_files, output_csv='transcriptions.csv'):\n",
        "    transcription_data = []\n",
        "\n",
        "    # Loop through all the audio files and transcribe them\n",
        "    for audio_file in audio_files:\n",
        "        if os.path.exists(audio_file):  # Check if the file exists\n",
        "            transcription = transcribe_audio(audio_file)\n",
        "            transcription_data.append([audio_file, transcription])\n",
        "        else:\n",
        "            transcription_data.append([audio_file, \"File not found\"])\n",
        "\n",
        "    # Create a DataFrame from the transcription data\n",
        "    df = pd.DataFrame(transcription_data, columns=['Audio File', 'Transcription'])\n",
        "\n",
        "    # Save the DataFrame to a CSV file\n",
        "    df.to_csv(output_csv, index=False)\n",
        "    print(f\"Transcriptions saved to {output_csv}\")\n",
        "\n",
        "# List of audio files you want to transcribe\n",
        "audio_files = [\n",
        "    'SandalWoodNewsStories_172.wav', 'SandalWoodNewsStories_98.wav', 'SandalWoodNewsStories_280.wav',\n",
        "    'SandalWoodNewsStories_279.wav', 'SandalWoodNewsStories_45.wav', 'SandalWoodNewsStories_167.wav',\n",
        "    'SandalWoodNewsStories_169.wav', 'SandalWoodNewsStories_239.wav', 'SandalWoodNewsStories_99.wav',\n",
        "    'SandalWoodNewsStories_286.wav', 'SandalWoodNewsStories_230.wav', 'SandalWoodNewsStories_305.wav',\n",
        "    'SandalWoodNewsStories_158.wav', 'SandalWoodNewsStories_156.wav', 'SandalWoodNewsStories_191.wav',\n",
        "    'SandalWoodNewsStories_229.wav', 'SandalWoodNewsStories_1.wav', 'SandalWoodNewsStories_107.wav',\n",
        "    'SandalWoodNewsStories_174.wav', 'SandalWoodNewsStories_299.wav', 'SandalWoodNewsStories_49.wav',\n",
        "    'SandalWoodNewsStories_159.wav', 'SandalWoodNewsStories_33.wav', 'SandalWoodNewsStories_197.wav',\n",
        "    'SandalWoodNewsStories_303.wav', 'SandalWoodNewsStories_306.wav', 'SandalWoodNewsStories_41.wav',\n",
        "    'SandalWoodNewsStories_278.wav', 'SandalWoodNewsStories_298.wav', 'SandalWoodNewsStories_291.wav',\n",
        "    'SandalWoodNewsStories_175.wav', 'SandalWoodNewsStories_179.wav', 'SandalWoodNewsStories_283.wav',\n",
        "    'SandalWoodNewsStories_35.wav', 'SandalWoodNewsStories_211.wav', 'SandalWoodNewsStories_9.wav',\n",
        "    'SandalWoodNewsStories_181.wav', 'SandalWoodNewsStories_282.wav', 'SandalWoodNewsStories_176.wav',\n",
        "    'SandalWoodNewsStories_53.wav', 'SandalWoodNewsStories_304.wav', 'SandalWoodNewsStories_173.wav',\n",
        "    'SandalWoodNewsStories_242.wav', 'SandalWoodNewsStories_249.wav', 'SandalWoodNewsStories_184.wav',\n",
        "    'SandalWoodNewsStories_36.wav', 'SandalWoodNewsStories_171.wav', 'SandalWoodNewsStories_257.wav',\n",
        "    'SandalWoodNewsStories_200.wav', 'SandalWoodNewsStories_23.wav', 'SandalWoodNewsStories_295.wav',\n",
        "    'SandalWoodNewsStories_146.wav', 'SandalWoodNewsStories_6.wav', 'SandalWoodNewsStories_215.wav',\n",
        "    'SandalWoodNewsStories_168.wav', 'SandalWoodNewsStories_148.wav', 'SandalWoodNewsStories_112.wav',\n",
        "    'SandalWoodNewsStories_297.wav', 'SandalWoodNewsStories_43.wav', 'SandalWoodNewsStories_284.wav',\n",
        "    'SandalWoodNewsStories_296.wav', 'SandalWoodNewsStories_223.wav', 'SandalWoodNewsStories_294.wav',\n",
        "    'SandalWoodNewsStories_2.wav', 'SandalWoodNewsStories_52.wav', 'SandalWoodNewsStories_42.wav',\n",
        "    'SandalWoodNewsStories_89.wav', 'SandalWoodNewsStories_63.wav', 'SandalWoodNewsStories_46.wav',\n",
        "    'SandalWoodNewsStories_287.wav', 'SandalWoodNewsStories_144.wav'\n",
        "]\n",
        "\n",
        "# Call the function to transcribe and save to CSV\n",
        "transcribe_all_audio_files(audio_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSqY55ZTX3MV",
        "outputId": "c9e3f784-c9ec-4bdb-b39d-7c78faa886e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcriptions saved to transcriptions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechrecognition pandas librosa matplotlib noisereduce soundfile scikit-learn numpy pyaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgnWS1IKgIFV",
        "outputId": "754384a3-4213-408f-bdcb-26d682f72d3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechrecognition\n",
            "  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting noisereduce\n",
            "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Collecting pyaudio\n",
            "  Downloading PyAudio-0.2.14.tar.gz (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.6)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2024.8.30)\n",
            "Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import speech_recognition as sr\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import noisereduce as nr\n",
        "import soundfile as sf\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "import numpy as np\n",
        "\n",
        "class SandalwoodQASystem:\n",
        "    def __init__(self, csv_path):\n",
        "        \"\"\"Initialize the QA System\"\"\"\n",
        "        # Load transcribed data\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "\n",
        "        # Initialize speech recognizer\n",
        "        self.recognizer = sr.Recognizer()\n",
        "\n",
        "        # Setup TF-IDF search\n",
        "        self.vectorizer = TfidfVectorizer()\n",
        "        self.tfidf_matrix = self.vectorizer.fit_transform(self.df['transcription'].fillna(''))\n",
        "\n",
        "    def preprocess_audio(self, audio_path):\n",
        "        \"\"\"Preprocess audio file to reduce noise\"\"\"\n",
        "        try:\n",
        "            # Load audio file\n",
        "            audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
        "\n",
        "            # Apply noise reduction\n",
        "            reduced_noise = nr.reduce_noise(\n",
        "                y=audio_data,\n",
        "                sr=sample_rate,\n",
        "                prop_decrease=1.0,\n",
        "                stationary=True\n",
        "            )\n",
        "\n",
        "            # Save preprocessed audio\n",
        "            preprocessed_path = \"preprocessed_audio.wav\"\n",
        "            sf.write(preprocessed_path, reduced_noise, sample_rate)\n",
        "\n",
        "            return preprocessed_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error preprocessing audio: {str(e)}\")\n",
        "            return audio_path\n",
        "\n",
        "    def visualize_audio(self, audio_path):\n",
        "        \"\"\"Visualize audio waveform and spectrogram\"\"\"\n",
        "        # Load audio\n",
        "        y, sr = librosa.load(audio_path)\n",
        "\n",
        "        # Create plot\n",
        "        plt.figure(figsize=(12, 8))\n",
        "\n",
        "        # Plot waveform\n",
        "        plt.subplot(2, 1, 1)\n",
        "        librosa.display.waveshow(y, sr=sr)\n",
        "        plt.title('Waveform')\n",
        "\n",
        "        # Plot spectrogram\n",
        "        plt.subplot(2, 1, 2)\n",
        "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
        "        librosa.display.specshow(D, sr=sr, x_axis='time', y_axis='log')\n",
        "        plt.colorbar(format='%+2.0f dB')\n",
        "        plt.title('Spectrogram')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def record_question(self):\n",
        "        \"\"\"Record audio question from user\"\"\"\n",
        "        print(\"Recording your question...\")\n",
        "\n",
        "        with sr.Microphone() as source:\n",
        "            # Adjust for ambient noise\n",
        "            print(\"Adjusting for ambient noise... Please wait.\")\n",
        "            self.recognizer.adjust_for_ambient_noise(source, duration=2)\n",
        "\n",
        "            print(\"Please speak your question now...\")\n",
        "            try:\n",
        "                # Record audio\n",
        "                audio = self.recognizer.listen(source, timeout=10, phrase_time_limit=30)\n",
        "\n",
        "                # Save audio to WAV file\n",
        "                with open(\"question.wav\", \"wb\") as f:\n",
        "                    f.write(audio.get_wav_data())\n",
        "\n",
        "                return \"question.wav\"\n",
        "\n",
        "            except sr.WaitTimeoutError:\n",
        "                print(\"No speech detected within timeout period\")\n",
        "                return None\n",
        "            except Exception as e:\n",
        "                print(f\"Error recording audio: {str(e)}\")\n",
        "                return None\n",
        "\n",
        "    def transcribe_audio(self, audio_path):\n",
        "        \"\"\"Transcribe audio using speech recognition\"\"\"\n",
        "        try:\n",
        "            # Preprocess audio\n",
        "            preprocessed_path = self.preprocess_audio(audio_path)\n",
        "\n",
        "            # Load audio file\n",
        "            with sr.AudioFile(preprocessed_path) as source:\n",
        "                audio = self.recognizer.record(source)\n",
        "\n",
        "                # Attempt transcription\n",
        "                try:\n",
        "                    # Try using Google Speech Recognition\n",
        "                    text = self.recognizer.recognize_google(audio, language='kn-IN')  # Kannada language\n",
        "                except sr.UnknownValueError:\n",
        "                    print(\"Speech Recognition could not understand the audio\")\n",
        "                    return None\n",
        "                except sr.RequestError as e:\n",
        "                    print(f\"Could not request results from Speech Recognition service; {e}\")\n",
        "                    return None\n",
        "\n",
        "                return text\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error transcribing audio: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "    def find_relevant_answers(self, question_text, top_k=3):\n",
        "        \"\"\"Find relevant answers using TF-IDF similarity\"\"\"\n",
        "        if not question_text:\n",
        "            return None\n",
        "\n",
        "        # Transform question\n",
        "        question_vector = self.vectorizer.transform([question_text])\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = []\n",
        "        for i in range(self.tfidf_matrix.shape[0]):\n",
        "            similarity = 1 - cosine(\n",
        "                question_vector.toarray().flatten(),\n",
        "                self.tfidf_matrix[i].toarray().flatten()\n",
        "            )\n",
        "            similarities.append(similarity)\n",
        "\n",
        "        # Get top matches\n",
        "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "        relevant_answers = self.df.iloc[top_indices]\n",
        "\n",
        "        return relevant_answers\n",
        "\n",
        "    def process_question(self):\n",
        "        \"\"\"Main function to process user's question\"\"\"\n",
        "        try:\n",
        "            # Record audio question\n",
        "            audio_file = self.record_question()\n",
        "            if not audio_file:\n",
        "                return None\n",
        "\n",
        "            # Visualize audio (optional)\n",
        "            self.visualize_audio(audio_file)\n",
        "\n",
        "            # Transcribe question\n",
        "            question_text = self.transcribe_audio(audio_file)\n",
        "            if not question_text:\n",
        "                return None\n",
        "\n",
        "            print(f\"\\nYour Question: {question_text}\")\n",
        "\n",
        "            # Find relevant answers\n",
        "            relevant_answers = self.find_relevant_answers(question_text)\n",
        "            if relevant_answers is not None:\n",
        "                print(\"\\nRelevant Answers:\")\n",
        "                for idx, row in relevant_answers.iterrows():\n",
        "                    print(f\"\\nAnswer {idx + 1}:\")\n",
        "                    print(f\"Transcription: {row['transcription']}\")\n",
        "                    if 'confidence_score' in row:\n",
        "                        print(f\"Confidence Score: {row['confidence_score']}\")\n",
        "                    print(f\"Source: {row['audio_path']}\")\n",
        "\n",
        "            return relevant_answers\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing question: {str(e)}\")\n",
        "            return None\n",
        "\n",
        "def main():\n",
        "    # Initialize the system\n",
        "    qa_system = SandalwoodQASystem('transcribed_dataset.csv')\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n=== Sandalwood Knowledge QA System ===\")\n",
        "        print(\"1. Ask a question\")\n",
        "        print(\"2. Exit\")\n",
        "\n",
        "        choice = input(\"\\nEnter your choice (1-2): \")\n",
        "\n",
        "        if choice == '1':\n",
        "            qa_system.process_question()\n",
        "        elif choice == '2':\n",
        "            print(\"Thank you for using the system!\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "6PYnzqTZgOAh",
        "outputId": "5c993697-3ed5-404d-cd7f-aaaa7490b0dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'speech_recognition'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-552c51a32b0e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspeech_recognition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'speech_recognition'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition\n",
        "!pip install librosa\n",
        "!pip install noisereduce\n",
        "!apt-get install portaudio19-dev python-pyaudio python3-pyaudio\n",
        "!pip install pyaudio\n",
        "!pip install soundfile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX0cExhjhIvI",
        "outputId": "8d5eac70-aa6e-4fd4-e1fb-ca202a14eb22"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Using cached SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n",
            "Using cached SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
            "Installing collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.11.0\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n",
            "Requirement already satisfied: noisereduce in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from noisereduce) (4.66.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from noisereduce) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->noisereduce) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "E: Unable to locate package python-pyaudio\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pyaudio)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import and mount google drive if needed\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import libraries for audio recording in Colab\n",
        "from IPython.display import Javascript, display, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def record_audio(filename):\n",
        "    AUDIO_HTML = \"\"\"\n",
        "    <script>\n",
        "    var my_div = document.createElement(\"DIV\");\n",
        "    var my_p = document.createElement(\"P\");\n",
        "    var my_btn = document.createElement(\"BUTTON\");\n",
        "    var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "    my_btn.appendChild(t);\n",
        "    my_div.appendChild(my_btn);\n",
        "    document.body.appendChild(my_div);\n",
        "\n",
        "    var base64data = 0;\n",
        "    var reader;\n",
        "    var recorder, gumStream;\n",
        "    var recordButton = my_btn;\n",
        "\n",
        "    var handleSuccess = function(stream) {\n",
        "      gumStream = stream;\n",
        "      var options = {\n",
        "        mimeType: 'audio/webm;codecs=opus',\n",
        "        audioBitsPerSecond:100000\n",
        "      };\n",
        "      recorder = new MediaRecorder(stream);\n",
        "      recorder.ondataavailable = function(e) {\n",
        "        var url = URL.createObjectURL(e.data);\n",
        "        var preview = document.createElement('audio');\n",
        "        preview.controls = true;\n",
        "        preview.src = url;\n",
        "        document.body.appendChild(preview);\n",
        "\n",
        "        reader = new FileReader();\n",
        "        reader.readAsDataURL(e.data);\n",
        "        reader.onloadend = function() {\n",
        "          base64data = reader.result;\n",
        "          resolve(base64data);\n",
        "        }\n",
        "      };\n",
        "      recorder.start();\n",
        "      };\n",
        "\n",
        "    recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "    navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "    function toggleRecording() {\n",
        "      if (recorder && recorder.state == \"recording\") {\n",
        "          recorder.stop();\n",
        "          gumStream.getAudioTracks()[0].stop();\n",
        "          recordButton.innerText = \"Saving...\";\n",
        "      }\n",
        "    }\n",
        "\n",
        "    function sleep(ms) {\n",
        "      return new Promise(resolve => setTimeout(resolve, ms));\n",
        "    }\n",
        "\n",
        "    var data = new Promise(async function(resolve, reject) {\n",
        "      recordButton.onclick = () => {\n",
        "      toggleRecording()\n",
        "      }\n",
        "    });\n",
        "\n",
        "    </script>\n",
        "    \"\"\"\n",
        "\n",
        "    display(HTML(AUDIO_HTML))\n",
        "    data = eval_js(\"data\")\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "\n",
        "    process = (np.frombuffer(binary, np.float32) * 32767).astype(np.int16)\n",
        "    fs = 44100\n",
        "\n",
        "    wavfile.write(filename, fs, process)\n",
        "    return filename\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcIkABudhLxd",
        "outputId": "bfc859fc-e063-40f3-ad37-4b8cd7a3b57e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.display import HTML, display\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import io\n",
        "import ffmpeg\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "\n",
        "# JavaScript and HTML for recording audio\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  recordButton.innerText = \"Recording... press to stop\";\n",
        "};\n",
        "\n",
        "recordButton.onclick = function() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Recording stopped. Processing...\";\n",
        "  } else {\n",
        "    navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "  }\n",
        "};\n",
        "\n",
        "async function getData() {\n",
        "  return new Promise(resolve => {\n",
        "    recordButton.onclick = function() {\n",
        "      if (recorder && recorder.state == \"recording\") {\n",
        "          recorder.stop();\n",
        "          gumStream.getAudioTracks()[0].stop();\n",
        "          recordButton.innerText = \"Recording stopped. Processing...\";\n",
        "          resolve(base64data.toString());\n",
        "      }\n",
        "    };\n",
        "  });\n",
        "}\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  # Display the audio recording HTML/JS\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"getData()\")  # This will wait for the recording to finish\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  # Convert the binary data into a WAV format using ffmpeg\n",
        "  process = (\n",
        "      ffmpeg\n",
        "      .input('pipe:0')\n",
        "      .output('pipe:1', format='wav')\n",
        "      .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True)\n",
        "  )\n",
        "  output, _ = process.communicate(input=binary)\n",
        "\n",
        "  # Read the output into an audio array\n",
        "  sr, audio = wav_read(io.BytesIO(output))\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "# Call get_audio to start recording and retrieve the audio array and sample rate\n",
        "audio, sr = get_audio()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        },
        "id": "M619o6_DjAu2",
        "outputId": "983e86bb-76e6-4941-96fe-e1fedf1a9fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = 0;\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  recorder = new MediaRecorder(stream);\n",
              "  recorder.ondataavailable = function(e) {            \n",
              "    var reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data); \n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "    }\n",
              "  };\n",
              "  recorder.start();\n",
              "  recordButton.innerText = \"Recording... press to stop\";\n",
              "};\n",
              "\n",
              "recordButton.onclick = function() {\n",
              "  if (recorder && recorder.state == \"recording\") {\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      recordButton.innerText = \"Recording stopped. Processing...\";\n",
              "  } else {\n",
              "    navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
              "  }\n",
              "};\n",
              "\n",
              "async function getData() {\n",
              "  return new Promise(resolve => {\n",
              "    recordButton.onclick = function() {\n",
              "      if (recorder && recorder.state == \"recording\") {\n",
              "          recorder.stop();\n",
              "          gumStream.getAudioTracks()[0].stop();\n",
              "          recordButton.innerText = \"Recording stopped. Processing...\";\n",
              "          resolve(base64data.toString());\n",
              "      }\n",
              "    };\n",
              "  });\n",
              "}\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install -y ffmpeg\n",
        "!pip install ffmpeg-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1NN9qDkj6rv",
        "outputId": "640435fe-d18d-473d-bc3f-8037ed4e6e9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:4 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:5 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,452 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,353 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,696 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,241 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,611 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,397 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,163 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,456 kB]\n",
            "Fetched 25.8 MB in 5s (5,691 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechrecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmgkM-2YVugI",
        "outputId": "632dc756-28a8-4f92-f369-d19ab062963a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechrecognition\n",
            "  Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from speechrecognition) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->speechrecognition) (2024.8.30)\n",
            "Downloading SpeechRecognition-3.11.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.8/32.8 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: speechrecognition\n",
            "Successfully installed speechrecognition-3.11.0\n"
          ]
        }
      ]
    }
  ]
}
